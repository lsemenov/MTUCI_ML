{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ данных высокой размерности, МТУСИ\n",
    "\n",
    "## Практическое задание 1\n",
    "\n",
    "### Общая информация\n",
    "Дата выдачи: 20.11.2021\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### О задании\n",
    "\n",
    "Практическое задание 1 посвящено изучению основных библиотек для анализа данных, а также линейных моделей и методов их обучения. Вы научитесь:\n",
    " * применять библиотеки NumPy и Pandas для осуществления желаемых преобразований;\n",
    " * подготавливать данные для обучения линейных моделей;\n",
    " * обучать линейную, Lasso и Ridge-регрессии при помощи модуля scikit-learn;\n",
    " * реализовывать обычный и стохастический градиентные спуски;\n",
    " * обучать линейную регрессию для произвольного функционала качества.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотеки для анализа данных\n",
    "\n",
    "### NumPy\n",
    "\n",
    "Во всех заданиях данного раздела запрещено использовать циклы  и list comprehensions. Под вектором и матрицей в данных заданиях понимается одномерный и двумерный numpy.array соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Реализуйте функцию, возвращающую максимальный элемент в векторе x среди элементов, перед которыми стоит нулевой. Для x = np.array([6, 2, 0, 3, 0, 0, 5, 7, 0]) ответом является 5. Если нулевых элементов нет, функция должна возвращать None.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_element(arr):\n",
    "    return arr.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вектор: [ 0  1  2  3  4  5  6  7  8  9 10 11], максимальное значение вектора: 11\n"
     ]
    }
   ],
   "source": [
    "arr = np.arange(12)\n",
    "print('Вектор: {}, максимальное значение вектора: {}'.format(arr, max_element(arr)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. ** Реализуйте функцию, принимающую на вход матрицу и некоторое число и возвращающую ближайший к числу элемент матрицы. Например: для X = np.arange(0,10).reshape((2, 5)) и v = 3.6 ответом будет 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_value(X, value):\n",
    "    X = X.reshape(X.size)\n",
    "    num = abs((X[0] / value) - 1)\n",
    "    ans = 0\n",
    "    \n",
    "    for i in range(1, X.size):\n",
    "\n",
    "        near = abs((X[i]/value) - 1)\n",
    "        near = round(near, 3)\n",
    "\n",
    "        if near <= 0.5 and near <= num:\n",
    "\n",
    "            num = near\n",
    "            ans = i\n",
    "                \n",
    "    return X[ans]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 : True\n",
      "8 : True\n",
      "-5 : True\n"
     ]
    }
   ],
   "source": [
    "# тест для задания 2\n",
    "test_data = {4.4:np.arange(20).reshape(2,10),\n",
    "            7.7:np.arange(5,20).reshape(3,5),\n",
    "            -5.5:np.arange(-10,20).reshape(3,10)}\n",
    "test_ans = {4.4:4,\n",
    "            7.7:8,\n",
    "            -5.5:-5}\n",
    "\n",
    "for i in test_data:\n",
    "    ans = nearest_value( test_data[i], i)\n",
    "    print(\"{} : {}\".format(ans, test_ans[i] == ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. ** Реализуйте функцию scale(X), которая принимает на вход матрицу и масштабирует каждый ее столбец (вычитает выборочное среднее и делит на стандартное отклонение). Убедитесь, что в функции не будет происходить деления на ноль. Протестируйте на случайной матрице (для её генерации можно использовать, например, функцию [numpy.random.randint](http://docs.scipy.org/doc/numpy/reference/generated/numpy.random.randint.html)).\n",
    "\n",
    "a.ravel()    #  \"Сплющивает\" массив до одной оси\n",
    "a.shape    #  Узнаем форму массива (кортеж на выходе)\n",
    "a.size    # узнать величину массива (число на выходе)\n",
    "\n",
    "a.reshape(2, 6)    #  Возвращает массив с измененной формой\n",
    "Обратите внимание на то, что возвращается новый массив\n",
    "в то время как исходный массив не изменяется.\n",
    "\n",
    " вернет среднее значение и стандартное отклонение mu, std_dev = norm.fit(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def scale(X):\n",
    "    ans = np.array([])\n",
    "    W = X.reshape(X.size)\n",
    "    \n",
    "    mu, std_dev = norm.fit(W)\n",
    "\n",
    "    for i in W:\n",
    "        if i != 0:\n",
    "            value = (i - mu) / std_dev\n",
    "            value = round(value, 4)\n",
    "            ans = np.append(ans, value)\n",
    "\n",
    "        else:\n",
    "            ans = np.append(ans, i)\n",
    "    \n",
    "    ans.resize(X.shape)\n",
    "    \n",
    "    return ans\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Изначальная матрица: \n",
      " [[5 5]\n",
      " [3 6]\n",
      " [5 9]\n",
      " [9 4]\n",
      " [8 6]] \n",
      " Преобразованная матрица:\n",
      " [[-0.513 -0.513]\n",
      " [-1.539  0.   ]\n",
      " [-0.513  1.539]\n",
      " [ 1.539 -1.026]\n",
      " [ 1.026  0.   ]]\n",
      "Изначальная матрица: \n",
      " [[ 9  2 17 11]\n",
      " [10 16 12 19]\n",
      " [13 15  2  3]\n",
      " [19 19 18  3]\n",
      " [ 9  8  4  6]] \n",
      " Преобразованная матрица:\n",
      " [[-0.295  -1.4751  1.0536  0.0421]\n",
      " [-0.1264  0.885   0.2107  1.3908]\n",
      " [ 0.3793  0.7165 -1.4751 -1.3065]\n",
      " [ 1.3908  1.3908  1.2222 -1.3065]\n",
      " [-0.295  -0.4636 -1.1379 -0.8008]]\n"
     ]
    }
   ],
   "source": [
    "# тест для задания 3\n",
    "test_data = {1:np.random.randint(10, size=(5,2)),\n",
    "             2: np.random.randint(20, size=(5,4))}\n",
    "\n",
    "for i in test_data:\n",
    "\n",
    "    print(\"Изначальная матрица: \\n {} \\n Преобразованная матрица:\\n {}\".format(test_data[i],  scale(test_data[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9, 19,  3,  9],\n",
       "       [13,  9, 19, 17],\n",
       "       [ 0, 13, 10, 14],\n",
       "       [ 5,  1, 16,  9],\n",
       "       [11, 19,  9,  9]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = {1:np.random.randint(10, size=(5,2)),\n",
    "             2: np.random.randint(20, size=(5,4))}\n",
    "test_data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Реализуйте функцию, которая для заданной матрицы находит:\n",
    " - определитель\n",
    " - след\n",
    " - наименьший и наибольший элементы\n",
    " - норму Фробениуса\n",
    " - собственные числа\n",
    " - обратную матрицу\n",
    "\n",
    "__Норма Фробениуса__ или, как её ещё называют Евклидова норма, — это квадратный корень сумм квадратов модулей элементов матрицы размера m × n:\n",
    "\n",
    "linalg.norm(a, ord=None) — норма матрицы a, по умолчанию норма Фробениуса для матриц и L2-норма для векторов; подробное описание возможных норм\n",
    "\n",
    "ord{non-zero int, inf, -inf, ‘fro’, ‘nuc’}, optional\n",
    "Order of the norm (see table under Notes). inf means numpy’s inf object. The default is None.\n",
    "\n",
    "__ИЛИ:__ как квадратный корень произведения следа этой матрицы и эрмитово-сопряжённой матрицы\n",
    "\n",
    "Для тестирования сгенерируйте матрицу с элементами из нормального распределения $\\mathcal{N}$(10,1)\n",
    "\n",
    "__Нормальное распределение__ является двухпараметрическим семейством распределений,Стандартным нормальным распределением называется нормальное распределение с математическим ожиданием  mu =0 и стандартным отклонением sigma =1.\n",
    "\n",
    "Здесь loc представляет среднее значение, а scale -стандартное отклонение, т. е. квадратный корень дисперсии.\n",
    "\n",
    "arr = np.random.normal(loc=1, scale=0.50, size=(500, 500))\n",
    "\n",
    "__Стандартное отклонение__\n",
    "Около 68 % значений из нормального распределения находятся на расстоянии не более одного стандартного отклонения σ от среднего; около 95 % значений лежат расстоянии не более двух стандартных отклонений; и 99,7 % не более трёх. Этот факт является частным случаем правила 3 сигм для нормальной выборки.\n",
    "\n",
    "__След матрицы__ - это сумма элементов квадратной матрицы, расположенных на главной диагонали и обозначается \n",
    "tr(A)\n",
    "\n",
    "np.trace(b)\n",
    "np.diagonal(b)\n",
    "\n",
    "\n",
    "__Обратимость__\n",
    "матрица обратима тогда и только тогда, когда она невырождена, то есть её определитель (|A|) не равен нулю. Для неквадратных матриц и вырожденных матриц обратных матриц не существует.\n",
    "\n",
    "__Обратная матрица__\n",
    "\n",
    "Обратной матрицей A-1 матрицы A называют матрицу, удовлетворяющую следующему равенству:\n",
    "\n",
    "$$ A x A^-1 = A ^-1 x A = E $$\n",
    "\n",
    "где – E это единичная матрица"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_stats(X):\n",
    "    #1 min elment in matrix\n",
    "    my_min = X.min()\n",
    "    \n",
    "    # max element in matrix\n",
    "    my_max = X.max()\n",
    "    \n",
    "    #2 eigenvalue\n",
    "    A_eig = np.linalg.eig(X)\n",
    "    \n",
    "    #3 matrix track\n",
    "    A_trace = np.diagonal(X)\n",
    "    \n",
    "    #4 norm Frobenius\n",
    "    A_normfro = np.linalg.norm(X)\n",
    "    \n",
    "    #5 determinant\n",
    "    A_det = np.linalg.det(X)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #6 inverse matrix\n",
    "    if A_det != 0:\n",
    "        A_inv_mat = np.linalg.inv(X)\n",
    "        \n",
    "    else:\n",
    "        A_inv_mat = \"матрица вырожденная\"\n",
    "        print(\"матрица вырожденная\")\n",
    "        \n",
    "    print (\"\"\"определитель:{0} \\n\\n след: {1} \\n\\n  наименьший элемент: {2} и наибольший элемент: {3} \\n\\n норму Фробениуса: {4} \\n\\n, собственные числа: {5} \\n\\n обратную матрицу: {6}\"\"\".format(A_det, A_trace, my_min, my_max, A_normfro, A_eig,  A_inv_mat,  ))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "определитель:4338.020314704308 \n",
      "\n",
      " след: [ 9.15128136  7.87085293 10.95115412  8.87974301 11.8397959  10.34207989\n",
      " 11.4267751  11.26784597  9.73211282 10.61010422] \n",
      "\n",
      "  наименьший элемент: 7.253332854039623 и наибольший элемент: 12.803223585003995 \n",
      "\n",
      " норму Фробениуса: 100.96867054322675 \n",
      "\n",
      ", собственные числа: (array([ 1.00372499e+02+0.j        , -2.22103517e-02+2.86111493j,\n",
      "       -2.22103517e-02-2.86111493j, -2.09193780e+00+0.j        ,\n",
      "        2.56266473e+00+0.j        , -3.02426876e-01+1.50039855j,\n",
      "       -3.02426876e-01-1.50039855j,  1.09574226e+00+0.37339545j,\n",
      "        1.09574226e+00-0.37339545j, -3.13690567e-01+0.j        ]), array([[ 0.33004651+0.j        ,  0.1265733 -0.00924955j,\n",
      "         0.1265733 +0.00924955j, -0.33052404+0.j        ,\n",
      "         0.26478009+0.j        ,  0.03424575+0.22212214j,\n",
      "         0.03424575-0.22212214j,  0.33667523+0.02476587j,\n",
      "         0.33667523-0.02476587j, -0.185379  +0.j        ],\n",
      "       [ 0.31649022+0.j        , -0.08060005+0.30505404j,\n",
      "        -0.08060005-0.30505404j,  0.28187277+0.j        ,\n",
      "        -0.25089096+0.j        ,  0.01785615-0.0057512j ,\n",
      "         0.01785615+0.0057512j ,  0.04794426-0.04832719j,\n",
      "         0.04794426+0.04832719j, -0.18723145+0.j        ],\n",
      "       [ 0.32518413+0.j        ,  0.37479455-0.08638522j,\n",
      "         0.37479455+0.08638522j,  0.35415132+0.j        ,\n",
      "        -0.12415662+0.j        ,  0.18375258-0.24077823j,\n",
      "         0.18375258+0.24077823j,  0.27008374+0.09246457j,\n",
      "         0.27008374-0.09246457j, -0.25060776+0.j        ],\n",
      "       [ 0.30364663+0.j        ,  0.21552903+0.09128263j,\n",
      "         0.21552903-0.09128263j, -0.26206627+0.j        ,\n",
      "        -0.37061758+0.j        , -0.28082472-0.00741759j,\n",
      "        -0.28082472+0.00741759j, -0.47552431+0.j        ,\n",
      "        -0.47552431-0.j        ,  0.63352999+0.j        ],\n",
      "       [ 0.32892018+0.j        ,  0.20560458+0.30277149j,\n",
      "         0.20560458-0.30277149j,  0.21132333+0.j        ,\n",
      "        -0.4401284 +0.j        ,  0.34727133-0.02236182j,\n",
      "         0.34727133+0.02236182j, -0.42265764-0.11177709j,\n",
      "        -0.42265764+0.11177709j, -0.01210637+0.j        ],\n",
      "       [ 0.30704339+0.j        ,  0.04958716+0.05915524j,\n",
      "         0.04958716-0.05915524j,  0.45515622+0.j        ,\n",
      "         0.34090939+0.j        ,  0.50985888+0.j        ,\n",
      "         0.50985888-0.j        ,  0.15669419-0.09575785j,\n",
      "         0.15669419+0.09575785j, -0.44685217+0.j        ],\n",
      "       [ 0.31081766+0.j        , -0.20225185-0.28879021j,\n",
      "        -0.20225185+0.28879021j, -0.30234193+0.j        ,\n",
      "        -0.09010971+0.j        , -0.45092347-0.17626769j,\n",
      "        -0.45092347+0.17626769j, -0.4173823 -0.04801014j,\n",
      "        -0.4173823 +0.04801014j,  0.41814661+0.j        ],\n",
      "       [ 0.30754064+0.j        , -0.25451232-0.0085114j ,\n",
      "        -0.25451232+0.0085114j , -0.47870593+0.j        ,\n",
      "         0.46559026+0.j        , -0.34080188+0.08219578j,\n",
      "        -0.34080188-0.08219578j, -0.0400424 +0.08098005j,\n",
      "        -0.0400424 -0.08098005j,  0.25288107+0.j        ],\n",
      "       [ 0.30755566+0.j        ,  0.01276449-0.37629693j,\n",
      "         0.01276449+0.37629693j,  0.18097181+0.j        ,\n",
      "         0.37212564+0.j        ,  0.10343369+0.0697612j ,\n",
      "         0.10343369-0.0697612j ,  0.27365533+0.05320697j,\n",
      "         0.27365533-0.05320697j, -0.1496563 +0.j        ],\n",
      "       [ 0.32359507+0.j        , -0.45913151+0.j        ,\n",
      "        -0.45913151-0.j        , -0.10979149+0.j        ,\n",
      "        -0.20216135+0.j        , -0.13352549+0.08202619j,\n",
      "        -0.13352549-0.08202619j,  0.28860136+0.05696193j,\n",
      "         0.28860136-0.05696193j, -0.07347554+0.j        ]])) \n",
      "\n",
      " обратную матрицу: [[ -0.44583605  -1.78219782  -0.10645425   3.99210885  -3.57033023\n",
      "    4.47858907  -0.47097651  -1.58316475  -2.09488572   1.896542  ]\n",
      " [ -0.05615118  -1.36630321  -0.07198681   2.85037553  -2.26828963\n",
      "    2.85072887  -0.27291     -1.11441159  -1.61321819   1.25621374]\n",
      " [ -0.29398641  -1.83415918   0.10215136   3.84610273  -3.46833692\n",
      "    3.87961266  -0.30203188  -1.45980026  -2.13860914   1.94641703]\n",
      " [  1.19883742   4.84810663   0.07703602 -10.56272452   9.16429091\n",
      "  -11.37421353   1.2418674    3.47500302   6.07551267  -4.91336554]\n",
      " [ -0.14906838  -0.13015284   0.47778748  -1.13347458   1.2369909\n",
      "   -1.12238591   0.43021413   0.59532948   0.18186574  -0.47131334]\n",
      " [ -0.73954709  -3.7466508    0.30924081   7.01634118  -6.28042566\n",
      "    8.10643013  -0.32160995  -2.29416128  -4.82181747   3.29762082]\n",
      " [  0.65215507   4.09385491  -0.50533814  -7.32505176   6.52878199\n",
      "   -8.3290595    0.53994139   2.62662522   4.92187118  -3.70428026]\n",
      " [  0.18436431   2.20801175  -0.21387347  -3.65420516   3.21634842\n",
      "   -4.14276717  -0.1052926    1.55454969   2.69394334  -1.96935677]\n",
      " [ -0.31112273  -1.69874791   0.08071267   2.94815937  -2.76473615\n",
      "    3.60126327  -0.27746042  -0.95801536  -2.08749093   1.69490349]\n",
      " [ -0.01676642  -0.60527609  -0.14811905   2.09786545  -1.84256596\n",
      "    2.12512661  -0.46446684  -0.88100987  -1.14587196   1.02831939]]\n"
     ]
    }
   ],
   "source": [
    "# тест для задания 4\n",
    "test_data = np.random.normal(loc=10, scale=1, size=(10,10))\n",
    "get_stats(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**5.** Повторите 100 раз следующий эксперимент: сгенерируйте две матрицы размера 10×10 из стандартного нормального распределения, перемножьте их (как матрицы) и найдите максимальный элемент. Какое среднее значение по экспериментам у максимальных элементов? 95-процентная квантиль?\n",
    "\n",
    "__Квантиль__ — это значение, ниже которого лежит определённое число наблюдений, соответствующих выбранной частоте.\n",
    "\n",
    "__Функция quantile()__ вычисляет q-й квантиль значений элементов массива или элементов вдоль указанной оси.\n",
    "\n",
    "Единственное отличие квантиля от процентиля - диапазон значений параметра q принимает значения в интервале [0, 1].\n",
    "\n",
    "Параметры:\n",
    "\n",
    "* a - массив NumPy или подобный массиву объект.\n",
    "\n",
    "Входные данные.\n",
    "\n",
    "* q - вещественное число, массив NumPy или подобный массиву объект.\n",
    "\n",
    "Квантиль или последовательность квантилей. Допустимые значения находятся в интервале [0, 1]..\n",
    "\n",
    "* axis - целое число или кортеж целых чисел, необязательный параметр.\n",
    "\n",
    "Указывает ось или оси по которым выполняется вычисление. По умолчанию axis = None, что соответствует вычислению квантиля \n",
    "так, словно a сжат до одной оси.\n",
    "\n",
    "* out - массив NumPy, необязательный параметр.\n",
    "\n",
    "Массив в который можно поместить результат функции. Данный массив должен соответствовать форме и типу данных результирующего массива функции (зачастую, тип данных может быть преобразован автоматически). Указание данного параметра, позволяет избежать лишней операции присваивания тем самым немного ускоряя работу вашего кода. Полезный параметр если вы очень часто обращаетесь к функции в цикле.\n",
    "\n",
    "* overwrite_input - True или False, необязательный параметр.\n",
    "\n",
    "Значение True позволяет использовать входной массив a для промежуточных вычислей, что позволяет сэкономит память но приводит к потере данных.\n",
    "\n",
    "* interpolation - {‘linear’, ‘lower’, ‘higher’, ‘midpoint’, ‘nearest’}, необязательный параметр.\n",
    "\n",
    "__Процентиль__ показывает процент наблюдений, лежащих ниже выбранного значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "среднее значение среди максимальных: 8.200469566288183 \n",
      " 95 процентный квантиль: 11.458829297713677 \n",
      " \n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_value = []\n",
    "\n",
    "for exp_num in range(100):\n",
    "    \n",
    "    MY_MATRIX1 = np.random.normal(loc=0, scale=1, size=(10,10))\n",
    "    MY_MATRIX2 = np.random.normal(loc=0, scale=1, size=(10,10))\n",
    "    MAT_DOT = np.dot(MY_MATRIX1, MY_MATRIX2)\n",
    "    \n",
    "    max_value.append(MAT_DOT.max())\n",
    "    \n",
    "\n",
    "   \n",
    "my_mean = np.mean(max_value)\n",
    "myquantile = np.quantile(max_value, q=0.95)\n",
    "\n",
    "print(\"среднее значение среди максимальных: {} \\n 95 процентный квантиль: {} \\n \".format(my_mean, myquantile))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "\n",
    "![](https://metrouk2.files.wordpress.com/2015/10/panda.jpg)\n",
    "\n",
    "#### Ответьте на вопросы о данных по авиарейсам в США за январь-апрель 2008 года.\n",
    "\n",
    "[Данные](https://www.dropbox.com/s/dvfitn93obn0rql/2008.csv?dl=0) и их [описание](http://stat-computing.org/dataexpo/2009/the-data.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\tMonth\t1-12\n",
    "\n",
    "3\tDayofMonth\t1-31\n",
    "\n",
    "4\tDayOfWeek\t1 (Monday) - 7 (Sunday)\n",
    "\n",
    "5\tDepTime\tactual departure time (local, hhmm)\n",
    "\n",
    "6\tCRSDepTime\tscheduled departure time (local, hhmm)\n",
    "\n",
    "7\tArrTime\tactual arrival time (local, hhmm)\n",
    "\n",
    "8\tCRSArrTime\tscheduled arrival time (local, hhmm)\n",
    "\n",
    "9\tUniqueCarrier\tunique carrier code\n",
    "\n",
    "10\tFlightNum\tflight number\n",
    "\n",
    "11\tTailNum\tplane tail number\n",
    "\n",
    "12\tActualElapsedTime\tin minutes\n",
    "\n",
    "13\tCRSElapsedTime\tin minutes\n",
    "\n",
    "14\tAirTime -\tin minutes\n",
    "\n",
    "15\tArrDelay - \tarrival delay, in minutes\n",
    "\n",
    "16\tDepDelay - \tdeparture delay, in minutes\n",
    "\n",
    "17\tOrigin\t - origin\n",
    "\n",
    "18\tDest  -\tdestination\n",
    "\n",
    "19\tDistance - \tin miles\n",
    "\n",
    "20\tTaxiIn\ttaxi in time, in minutes\n",
    "\n",
    "21\tTaxiOut\ttaxi out time in minutes\n",
    "\n",
    "22\tCancelled\twas the flight cancelled?\n",
    "\n",
    "23\tCancellationCode\treason for cancellation (A = carrier, B = weather, C = NAS, D = security)\n",
    "\n",
    "24\tDiverted\t1 = yes, 0 = no\n",
    "\n",
    "25\tCarrierDelay\tin minutes\n",
    "\n",
    "26\tWeatherDelay\tin minutes\n",
    "\n",
    "27\tNASDelay\tin minutes\n",
    "\n",
    "28\tSecurityDelay\tin minutes\n",
    "\n",
    "29\tLateAircraftDelay\tin minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В таблице (70000, 29) строка, таблица представляет из себя данные по авиарейсам\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>...</th>\n",
       "      <th>TaxiIn</th>\n",
       "      <th>TaxiOut</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>CancellationCode</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>CarrierDelay</th>\n",
       "      <th>WeatherDelay</th>\n",
       "      <th>NASDelay</th>\n",
       "      <th>SecurityDelay</th>\n",
       "      <th>LateAircraftDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69990</th>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>1630</td>\n",
       "      <td>1714.0</td>\n",
       "      <td>1715</td>\n",
       "      <td>MQ</td>\n",
       "      <td>3092</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69991</th>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>914.0</td>\n",
       "      <td>920</td>\n",
       "      <td>1235.0</td>\n",
       "      <td>1231</td>\n",
       "      <td>NW</td>\n",
       "      <td>241</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69992</th>\n",
       "      <td>2008</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>754.0</td>\n",
       "      <td>801</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>1039</td>\n",
       "      <td>UA</td>\n",
       "      <td>885</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69993</th>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>1400</td>\n",
       "      <td>1501.0</td>\n",
       "      <td>1455</td>\n",
       "      <td>MQ</td>\n",
       "      <td>3547</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69994</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>920.0</td>\n",
       "      <td>925</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>1118</td>\n",
       "      <td>OH</td>\n",
       "      <td>5218</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1829.0</td>\n",
       "      <td>1840</td>\n",
       "      <td>2137.0</td>\n",
       "      <td>2149</td>\n",
       "      <td>DL</td>\n",
       "      <td>794</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>1125</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>1314</td>\n",
       "      <td>OO</td>\n",
       "      <td>6159</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>2008</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1012</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>1132</td>\n",
       "      <td>YV</td>\n",
       "      <td>7058</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>1900</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>2139</td>\n",
       "      <td>NW</td>\n",
       "      <td>641</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>859.0</td>\n",
       "      <td>900</td>\n",
       "      <td>959.0</td>\n",
       "      <td>1005</td>\n",
       "      <td>WN</td>\n",
       "      <td>510</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Month  DayofMonth  DayOfWeek  DepTime  CRSDepTime  ArrTime  \\\n",
       "69990  2008     12          23          2   1627.0        1630   1714.0   \n",
       "69991  2008      4          24          4    914.0         920   1235.0   \n",
       "69992  2008     11           4          2    754.0         801   1027.0   \n",
       "69993  2008      2          28          4   1410.0        1400   1501.0   \n",
       "69994  2008      1          26          6    920.0         925   1110.0   \n",
       "69995  2008      5          12          1   1829.0        1840   2137.0   \n",
       "69996  2008      5          11          7   1149.0        1125   1336.0   \n",
       "69997  2008      9          24          3   1012.0        1012   1132.0   \n",
       "69998  2008      2          18          1   1906.0        1900   2200.0   \n",
       "69999  2008     12           6          6    859.0         900    959.0   \n",
       "\n",
       "       CRSArrTime UniqueCarrier  FlightNum  ... TaxiIn  TaxiOut  Cancelled  \\\n",
       "69990        1715            MQ       3092  ...    9.0     12.0          0   \n",
       "69991        1231            NW        241  ...   11.0     21.0          0   \n",
       "69992        1039            UA        885  ...    5.0     17.0          0   \n",
       "69993        1455            MQ       3547  ...    5.0     14.0          0   \n",
       "69994        1118            OH       5218  ...   12.0     13.0          0   \n",
       "69995        2149            DL        794  ...   22.0     20.0          0   \n",
       "69996        1314            OO       6159  ...    4.0     13.0          0   \n",
       "69997        1132            YV       7058  ...    7.0     10.0          0   \n",
       "69998        2139            NW        641  ...   20.0     22.0          0   \n",
       "69999        1005            WN        510  ...    2.0     12.0          0   \n",
       "\n",
       "       CancellationCode  Diverted  CarrierDelay WeatherDelay NASDelay  \\\n",
       "69990               NaN         0           NaN          NaN      NaN   \n",
       "69991               NaN         0           NaN          NaN      NaN   \n",
       "69992               NaN         0           NaN          NaN      NaN   \n",
       "69993               NaN         0           NaN          NaN      NaN   \n",
       "69994               NaN         0           NaN          NaN      NaN   \n",
       "69995               NaN         0           NaN          NaN      NaN   \n",
       "69996               NaN         0           0.0          0.0      0.0   \n",
       "69997               NaN         0           NaN          NaN      NaN   \n",
       "69998               NaN         0           0.0          0.0     15.0   \n",
       "69999               NaN         0           NaN          NaN      NaN   \n",
       "\n",
       "       SecurityDelay  LateAircraftDelay  \n",
       "69990            NaN                NaN  \n",
       "69991            NaN                NaN  \n",
       "69992            NaN                NaN  \n",
       "69993            NaN                NaN  \n",
       "69994            NaN                NaN  \n",
       "69995            NaN                NaN  \n",
       "69996            0.0               22.0  \n",
       "69997            NaN                NaN  \n",
       "69998            0.0                6.0  \n",
       "69999            NaN                NaN  \n",
       "\n",
       "[10 rows x 29 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "frame = pd.read_csv(\"2008.csv\", header=0, sep=',')\n",
    "print(\"В таблице {} строка, таблица представляет из себя данные по авиарейсам\".format(frame.shape))\n",
    "frame.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                     0\n",
       "Month                    0\n",
       "DayofMonth               0\n",
       "DayOfWeek                0\n",
       "DepTime               1399\n",
       "CRSDepTime               0\n",
       "ArrTime               1556\n",
       "CRSArrTime               0\n",
       "UniqueCarrier            0\n",
       "FlightNum                0\n",
       "TailNum                820\n",
       "ActualElapsedTime     1582\n",
       "CRSElapsedTime           9\n",
       "AirTime               1582\n",
       "ArrDelay              1582\n",
       "DepDelay              1399\n",
       "Origin                   0\n",
       "Dest                     0\n",
       "Distance                 0\n",
       "TaxiIn                1556\n",
       "TaxiOut               1406\n",
       "Cancelled                0\n",
       "CancellationCode     68589\n",
       "Diverted                 0\n",
       "CarrierDelay         54747\n",
       "WeatherDelay         54747\n",
       "NASDelay             54747\n",
       "SecurityDelay        54747\n",
       "LateAircraftDelay    54747\n",
       "dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** Какая из причин отмены рейса (`CancellationCode`) была самой частой? (расшифровки кодов можно найти в описании данных)\n",
    "\n",
    "(A = carrier, B = weather, C = NAS, D = security)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ОТВЕТ:Наиболее частая отмена рейсов: A - carrier\n"
     ]
    }
   ],
   "source": [
    "cancelled_reason = frame.groupby(\"CancellationCode\")[\"Cancelled\"].sum().idxmax()\n",
    "print(\"ОТВЕТ:Наиболее частая отмена рейсов: {} - carrier\".format(cancelled_reason))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.** Найдите среднее, минимальное и максимальное расстояние, пройденное самолетом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ОТВЕТ:Масимальное растояние(в милях) пройденное самолетом: 4962 \n",
      " Минимальное расстояние(в милях): 31 \n",
      " Среднее расстояние(в милях): 724.51\n"
     ]
    }
   ],
   "source": [
    "max_dist = frame[\"Distance\"].max()\n",
    "min_dist = frame[\"Distance\"].min()\n",
    "mean_dist = frame[\"Distance\"].mean()\n",
    "\n",
    "print(\"ОТВЕТ:Масимальное растояние(в милях) пройденное самолетом: {} \\n Минимальное расстояние(в милях): {} \\n Среднее расстояние(в милях): {:0.2f}\".format(max_dist, min_dist, mean_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.** Не выглядит ли подозрительным минимальное пройденное расстояние? В какие дни и на каких рейсах оно было? Какое расстояние было пройдено этими же рейсами в другие дни?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ОТВЕТ: Номер рейса и день с мин. расстоянием \n",
      "\n",
      "        Month  DayofMonth  FlightNum  Distance\n",
      "1116      12          30         65        31\n",
      "27534      3          11         64        31\n",
      "46082      8           9         65        31\n",
      "48112      2          28         64        31 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>64</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>65</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>64</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>65</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>64</td>\n",
       "      <td>2381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66529</th>\n",
       "      <td>65</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67172</th>\n",
       "      <td>64</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68264</th>\n",
       "      <td>65</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68338</th>\n",
       "      <td>65</td>\n",
       "      <td>2454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69305</th>\n",
       "      <td>65</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FlightNum  Distance\n",
       "501           64       533\n",
       "1116          65        31\n",
       "1389          64       680\n",
       "1517          65       680\n",
       "2619          64      2381\n",
       "...          ...       ...\n",
       "66529         65        82\n",
       "67172         64       533\n",
       "68264         65       386\n",
       "68338         65      2454\n",
       "69305         65      1005\n",
       "\n",
       "[75 rows x 2 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "frame = pd.read_csv(\"2008.csv\", header=0, sep=',')\n",
    "\n",
    "# Очищаем от отменённых рейсов\n",
    "frame = frame[(frame[\"Cancelled\"] == 0)]\n",
    "\n",
    "# Только с минимальным пройденнным расстоянием\n",
    "my_frame = frame[frame[\"Distance\"] <= 31][[\"Month\", \"DayofMonth\", \"FlightNum\", \"Distance\"]]\n",
    "print(\"ОТВЕТ: Номер рейса и день с мин. расстоянием \\n\\n {} \".format(my_frame))\n",
    "\n",
    "#Какое расстояние было пройдено этими же рейсами в другие дни?\n",
    "#flight_num = my_frame[\"FlightNum\"].unique()\n",
    "#frame[frame[\"Distance\"] <= 31][ \"FlightNum\"].unique())\n",
    "\n",
    "frame[(frame[\"FlightNum\"] == 65 ) | (frame[\"FlightNum\"] == 64 ) ][[\"FlightNum\",\"Distance\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9.** Из какого аэропорта было произведено больше всего вылетов? В каком городе он находится?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "frame = pd.read_csv(\"2008.csv\", header=0, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ОТВЕТ: Аэропорта с наибольшем количеством вылетов:\n",
      "ATL    4078\n",
      "Name: Origin, dtype: int64 PS: ATL-Атланта\n"
     ]
    }
   ],
   "source": [
    "# Очищаем от отменённых рейсов\n",
    "frame = frame[(frame[\"Cancelled\"] == 0)]\n",
    "\n",
    "# подсчитываем общее количество вылетов для каждого аэропорта и находим максимальное значение\n",
    "ans = frame[\"Origin\"].value_counts()\n",
    "ans = ans[ans == ans.max()]\n",
    "\n",
    "print(\"ОТВЕТ: Аэропорта с наибольшем количеством вылетов:\\n{}\".format(ans), \"PS: ATL-Атланта\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10.** Найдите для каждого аэропорта среднее время полета (`AirTime`) по всем вылетевшим из него рейсам. Какой аэропорт имеет наибольшее значение этого показателя?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ОТВЕТ:Cреднее время полета (AirTime) по всем вылетевшем из него рейсам: \n",
      "Origin\n",
      "ABE    88.266667\n",
      "ABI    36.400000\n",
      "ABQ    93.454321\n",
      "ABY    35.714286\n",
      "ACK    50.800000\n",
      "         ...    \n",
      "WRG    18.000000\n",
      "XNA    85.945736\n",
      "YAK    35.900000\n",
      "YKM    79.000000\n",
      "YUM    47.470588\n",
      "Name: AirTime, Length: 296, dtype: float64 \n",
      "\n",
      "\n",
      "ОТВЕТ:Аэропорт с наибольшим значением среднего время полёта:\n",
      "Origin\n",
      "SJU    205.2\n",
      "Name: AirTime, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "frame = pd.read_csv(\"2008.csv\", header=0, sep=',')\n",
    "\n",
    "# Очищаем от отменённых рейсов\n",
    "frame = frame[(frame[\"Cancelled\"] == 0)]\n",
    "\n",
    "# среднее время полета (AirTime) по всем вылетевшем из него рейсам\n",
    "frame1 = frame.groupby(\"Origin\")[\"AirTime\"].mean()\n",
    "\n",
    "# наибольшее значение среднего время полёта соответствуеь (San Juan Airport)\n",
    "frame2 = frame1[frame1==frame1.max()]\n",
    "\n",
    "print(\"ОТВЕТ:Cреднее время полета (AirTime) по всем вылетевшем из него рейсам: \\n{} \\n\\n\".format(frame1))\n",
    "print(\"ОТВЕТ:Аэропорт с наибольшим значением среднего время полёта:\\n{}\".format(frame2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11.** Найдите аэропорт, у которого наибольшая доля задержанных (`DepDelay > 0`) рейсов. Исключите при этом из рассмотрения аэропорты, из которых было отправлено меньше 1000 рейсов (используйте функцию `filter` после `groupby`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ОТВЕТ: Аэропорт с наибольшим количеством задержанных вылетов \n",
      "\n",
      "Origin\n",
      "EWR    0.511159\n",
      "Name: FlightNum, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "frame = pd.read_csv(\"2008.csv\", header=0, sep=',')\n",
    "\n",
    "\n",
    "#1.Исключим  аэропорты c  отправлением меньше 1000 рейсов\n",
    "fn_flt= frame.groupby('Origin').filter(lambda x: x['Origin'].value_counts() > 1000)\n",
    "\n",
    "#2.сортируем аэропорты где имеется задержка в отправлении DepDelay \n",
    "num_dep_delay = fn_flt[fn_flt[\"DepDelay\"] > 0].groupby(\"Origin\")[\"FlightNum\"].count()\n",
    "num_dep = fn_flt.groupby(\"Origin\")[\"FlightNum\"].count()\n",
    "\n",
    "#3.выбираем аэропортs у которых доля задерженных вылетов наибольшая\n",
    "ans = num_dep_delay.div(num_dep)\n",
    "ans = ans[ans == ans.max()]\n",
    "\n",
    "#print(\"Количестов вылетов с задержкой:\\n\\n \", num_dep_delay, \"\\n\\n Общее количестов вылетов: \", num_dep)\n",
    "print(\"ОТВЕТ: Аэропорт с наибольшим количеством задержанных вылетов \\n\\n{}\".format(ans))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейная регрессия\n",
    "\n",
    "В этой части мы разберемся с линейной регрессией, способами её обучения и измерением качества ее прогнозов. \n",
    "\n",
    "Будем рассматривать датасет из предыдущей части задания для предсказания времени задержки отправления рейса в минутах (DepDelay). Отметим, что под задержкой подразумевается не только опоздание рейса относительно планируемого времени вылета, но и отправление до планируемого времени.\n",
    "\n",
    "### Подготовка данных\n",
    "\n",
    "**12.** Считайте выборку из файла при помощи функции pd.read_csv и ответьте на следующие вопросы:\n",
    "   - Имеются ли в данных пропущенные значения?\n",
    "   - Сколько всего пропущенных элементов в таблице \"объект-признак\"?\n",
    "   - Сколько объектов имеют хотя бы один пропуск?\n",
    "   - Сколько признаков имеют хотя бы одно пропущенное значение?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"2008.csv\", header=0, sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Результат:__\n",
    "\n",
    "* Имеются ли в данных пропущенные значения? - Да\n",
    "* Сколько всего пропущенных элементов в таблице \"объект-признак\"? - 355215\n",
    "* Сколько объектов имеют хотя бы один пропуск? - 16\n",
    "* Сколько признаков имеют хотя бы одно пропущенное значение? 70000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                     0\n",
       "Month                    0\n",
       "DayofMonth               0\n",
       "DayOfWeek                0\n",
       "DepTime               1399\n",
       "CRSDepTime               0\n",
       "ArrTime               1556\n",
       "CRSArrTime               0\n",
       "UniqueCarrier            0\n",
       "FlightNum                0\n",
       "TailNum                820\n",
       "ActualElapsedTime     1582\n",
       "CRSElapsedTime           9\n",
       "AirTime               1582\n",
       "ArrDelay              1582\n",
       "DepDelay              1399\n",
       "Origin                   0\n",
       "Dest                     0\n",
       "Distance                 0\n",
       "TaxiIn                1556\n",
       "TaxiOut               1406\n",
       "Cancelled                0\n",
       "CancellationCode     68589\n",
       "Diverted                 0\n",
       "CarrierDelay         54747\n",
       "WeatherDelay         54747\n",
       "NASDelay             54747\n",
       "SecurityDelay        54747\n",
       "LateAircraftDelay    54747\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355215"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.isnull().sum(axis=1) > 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы понимаете, также не имеет смысла рассматривать при решении поставленной задачи объекты с пропущенным значением целевой переменной. В связи с этим ответьте на следующие вопросы и выполните соответствующие действия:\n",
    "\n",
    "\n",
    "Исключите из выборки объекты **с пропущенным значением целевой переменной и со значением целевой переменной, равным 0**, а также при необходимости исключите признаки в соответствии с вашим ответом на последний вопрос из списка и выделите целевую переменную в отдельный вектор, исключив её из матрицы \"объект-признак\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ответ:__\n",
    "\n",
    "__1. Имеются ли пропущенные значения в целевой переменной?__\n",
    "\n",
    "ДА\n",
    "\n",
    "__2. Проанализируйте объекты с пропущенными значениями целевой переменной. Чем вызвано это явление? Что их объединяет? Можно ли в связи с этим, на ваш взгляд, исключить какие-то признаки из рассмотрения? Обоснуйте свою точку зрения.__\n",
    "\n",
    "Предобработать бъекты с пропущенными значениями целевой переменой, можно удалив их из датасета, главное не удалять слишком много, чтобы оставалась возможность провести надежный анализ. Т.К. возсожен риск потери ценной информации.  Внашем случае целевая переменная отсутствует в 1399 случаях , это 0.01 % от всех значений целевой переменной. \n",
    " \n",
    " Пропуски в значениях целевой переменной, возможно связанны с пропусками в ключевых признаках.\n",
    " \n",
    " Признаки CarrierDelay, WeatherDelay, NASDelay, SecurityDelay, LateAircraftDelay в дальнейшем рассмотрении будут удалены т.к. имеет наибольшее количество пропущенных значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1399"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"DepDelay\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропуски в значениях целевой переменной, возможно связанны с пропусками в ключевых признаках. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>...</th>\n",
       "      <th>TaxiIn</th>\n",
       "      <th>TaxiOut</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>CancellationCode</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>CarrierDelay</th>\n",
       "      <th>WeatherDelay</th>\n",
       "      <th>NASDelay</th>\n",
       "      <th>SecurityDelay</th>\n",
       "      <th>LateAircraftDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1940</td>\n",
       "      <td>AA</td>\n",
       "      <td>484</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>930</td>\n",
       "      <td>EV</td>\n",
       "      <td>4772</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1355</td>\n",
       "      <td>FL</td>\n",
       "      <td>816</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>758</td>\n",
       "      <td>NW</td>\n",
       "      <td>1281</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005</td>\n",
       "      <td>UA</td>\n",
       "      <td>1251</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69818</th>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1800</td>\n",
       "      <td>MQ</td>\n",
       "      <td>3627</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69836</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1030</td>\n",
       "      <td>MQ</td>\n",
       "      <td>3254</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69884</th>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2116</td>\n",
       "      <td>NW</td>\n",
       "      <td>1430</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69918</th>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>742</td>\n",
       "      <td>EV</td>\n",
       "      <td>4715</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69949</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1729</td>\n",
       "      <td>MQ</td>\n",
       "      <td>4198</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1399 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Month  DayofMonth  DayOfWeek  DepTime  CRSDepTime  ArrTime  \\\n",
       "11     2008      3           6          4      NaN        1605      NaN   \n",
       "78     2008      1          19          6      NaN         750      NaN   \n",
       "103    2008      7          24          4      NaN        1230      NaN   \n",
       "112    2008      2           4          1      NaN         620      NaN   \n",
       "128    2008      1          21          1      NaN        1838      NaN   \n",
       "...     ...    ...         ...        ...      ...         ...      ...   \n",
       "69818  2008      6           9          1      NaN        1645      NaN   \n",
       "69836  2008      1          25          5      NaN         938      NaN   \n",
       "69884  2008     12          26          5      NaN        1935      NaN   \n",
       "69918  2008      3           1          6      NaN         600      NaN   \n",
       "69949  2008      1          21          1      NaN        1630      NaN   \n",
       "\n",
       "       CRSArrTime UniqueCarrier  FlightNum  ... TaxiIn  TaxiOut  Cancelled  \\\n",
       "11           1940            AA        484  ...    NaN      NaN          1   \n",
       "78            930            EV       4772  ...    NaN      NaN          1   \n",
       "103          1355            FL        816  ...    NaN      NaN          1   \n",
       "112           758            NW       1281  ...    NaN      NaN          1   \n",
       "128          2005            UA       1251  ...    NaN      NaN          1   \n",
       "...           ...           ...        ...  ...    ...      ...        ...   \n",
       "69818        1800            MQ       3627  ...    NaN      NaN          1   \n",
       "69836        1030            MQ       3254  ...    NaN      NaN          1   \n",
       "69884        2116            NW       1430  ...    NaN      NaN          1   \n",
       "69918         742            EV       4715  ...    NaN      NaN          1   \n",
       "69949        1729            MQ       4198  ...    NaN      NaN          1   \n",
       "\n",
       "       CancellationCode  Diverted  CarrierDelay WeatherDelay NASDelay  \\\n",
       "11                    B         0           NaN          NaN      NaN   \n",
       "78                    B         0           NaN          NaN      NaN   \n",
       "103                   A         0           NaN          NaN      NaN   \n",
       "112                   B         0           NaN          NaN      NaN   \n",
       "128                   A         0           NaN          NaN      NaN   \n",
       "...                 ...       ...           ...          ...      ...   \n",
       "69818                 C         0           NaN          NaN      NaN   \n",
       "69836                 B         0           NaN          NaN      NaN   \n",
       "69884                 B         0           NaN          NaN      NaN   \n",
       "69918                 A         0           NaN          NaN      NaN   \n",
       "69949                 C         0           NaN          NaN      NaN   \n",
       "\n",
       "       SecurityDelay  LateAircraftDelay  \n",
       "11               NaN                NaN  \n",
       "78               NaN                NaN  \n",
       "103              NaN                NaN  \n",
       "112              NaN                NaN  \n",
       "128              NaN                NaN  \n",
       "...              ...                ...  \n",
       "69818            NaN                NaN  \n",
       "69836            NaN                NaN  \n",
       "69884            NaN                NaN  \n",
       "69918            NaN                NaN  \n",
       "69949            NaN                NaN  \n",
       "\n",
       "[1399 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"DepDelay\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13.** Обратите внимание, что признаки DepTime, CRSDepTime, ArrTime, CRSArrTime приведены в формате hhmm, в связи с чем будет не вполне корректно рассматривать их как вещественные.\n",
    "\n",
    "Преобразуйте каждый признак FeatureName из указанных в пару новых признаков FeatureName\\_Hour, FeatureName\\_Minute, разделив каждое из значений на часы и минуты. Не забудьте при этом исключить исходный признак из выборки. В случае, если значение признака отсутствует, значения двух новых признаков, его заменяющих, также должны отсутствовать. \n",
    "\n",
    "Например, признак DepTime необходимо заменить на пару признаков DepTime_Hour, DepTime_Minute. При этом, например, значение 155 исходного признака будет преобразовано в значения 1 и 55 признаков DepTime_Hour, DepTime_Minute соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"2008.csv\", header=0, sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in [\"DepTime\", \"CRSDepTime\", \"ArrTime\", \"CRSArrTime\", \"ActualElapsedTime\", \"CRSElapsedTime\"]:\n",
    "    \n",
    "    # маска для вещественных значений\n",
    "    features_mask = df[feature].isna()\n",
    "    \n",
    "    \n",
    "    df[\"{}_Hour\".format(feature)] = df[feature][~features_mask] // 100\n",
    "    \n",
    "    df[\"{}_Minute\".format(feature)] = df[feature][~features_mask] % 100\n",
    "    \n",
    "    df.drop([feature], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14.** Некоторые из признаков, отличных от целевой переменной, могут оказывать чересчур значимое влияние на прогноз, поскольку по своему смыслу содержат большую долю информации о значении целевой переменной. Изучите описание датасета и исключите признаки, сильно коррелирующие с ответами. Ваш выбор признаков для исключения из выборки обоснуйте. Кроме того, исключите признаки TailNum и Year.\n",
    "\n",
    "__Ответ:__ Признаки подлежат исключению, т.к. имеют много пропусков более 70%, практика с заменой не возможна. В противном случае это приведёт к зашумлению и утери полезной информации, связь с целевой переменной потеряется. (\"CancellationCode\",\"CarrierDelay\", \"WeatherDelay\", \"NASDelay \", \"SecurityDelay\", \"LateAircraftDelay\")\n",
    "UniqueCarrier - \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = df[\"DepDelay\"]\n",
    "y = y.fillna(y.mean())\n",
    "\n",
    "df.drop(['DepDelay', 'TailNum', 'Year', \"CancellationCode\",\n",
    "         \"CarrierDelay\", \"WeatherDelay\",\"NASDelay\",\"SecurityDelay\",\n",
    "         \"LateAircraftDelay\", \"TaxiIn\", \"TaxiOut\"], axis=1,  inplace=True)\n",
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Month                          0\n",
       "DayofMonth                     0\n",
       "DayOfWeek                      0\n",
       "UniqueCarrier                  0\n",
       "FlightNum                      0\n",
       "AirTime                     1582\n",
       "ArrDelay                    1582\n",
       "Origin                         0\n",
       "Dest                           0\n",
       "Distance                       0\n",
       "Cancelled                      0\n",
       "Diverted                       0\n",
       "DepTime_Hour                1399\n",
       "DepTime_Minute              1399\n",
       "CRSDepTime_Hour                0\n",
       "CRSDepTime_Minute              0\n",
       "ArrTime_Hour                1556\n",
       "ArrTime_Minute              1556\n",
       "CRSArrTime_Hour                0\n",
       "CRSArrTime_Minute              0\n",
       "ActualElapsedTime_Hour      1582\n",
       "ActualElapsedTime_Minute    1582\n",
       "CRSElapsedTime_Hour            9\n",
       "CRSElapsedTime_Minute          9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15.** Приведем данные к виду, пригодному для обучения линейных моделей. Для этого вещественные признаки надо отмасштабировать, а категориальные — привести к числовому виду. Также надо устранить пропуски в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первую очередь поймем, зачем необходимо применять масштабирование. Следующие ячейки с кодом построят гистограммы для 3 вещественных признаков выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Пропуски, замена на среднии\n",
    "#2. One-hot кодирование\n",
    "#3. Нормализация\\\\стандартизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X['DepTime_Hour'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'TaxiIn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'TaxiIn'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-f05e2c785e37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TaxiIn'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'TaxiIn'"
     ]
    }
   ],
   "source": [
    "X['TaxiIn'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['FlightNum'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какую проблему вы наблюдаете на этих графиках? Как масштабирование поможет её исправить?\n",
    "\n",
    "__ОТВЕТ:__ Наблюдаются выбросы, большие отклонения, котоорые будут негативно влиять на предсказание модели), необходимо масштабировать признаки, используя scklearn инструменты StandartScaler/minMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые из признаков в нашем датасете являются категориальными. Типичным подходом к работе с ними является бинарное, или [one-hot-кодирование](https://en.wikipedia.org/wiki/One-hot).\n",
    "\n",
    "Реализуйте функцию transform_data, которая принимает на вход DataFrame с признаками и выполняет следующие шаги:\n",
    "1. Замена пропущенных значений на нули для вещественных признаков и на строки 'nan' для категориальных.\n",
    "2. Масштабирование вещественных признаков с помощью [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html).\n",
    "3. One-hot-кодирование категориальных признаков с помощью [DictVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) или функции [pd.get_dummies](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html).\n",
    "\n",
    "get_dummies(drop_first=True). - Необходимо удалить один из столбцов, созданных для каждого признака. Для этого в надо поставить\n",
    "\n",
    "Метод должен возвращать преобразованный DataFrame, который должна состоять из масштабированных вещественных признаков и закодированных категориальных (исходные признаки должны быть исключены из выборки)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AirTime                     0\n",
       "ArrDelay                    0\n",
       "DepTime_Hour                0\n",
       "DepTime_Minute              0\n",
       "ArrTime_Hour                0\n",
       "ArrTime_Minute              0\n",
       "ActualElapsedTime_Hour      0\n",
       "ActualElapsedTime_Minute    0\n",
       "CRSElapsedTime_Hour         0\n",
       "CRSElapsedTime_Minute       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# заменим пропуски на \"0\" в вещественных признаках\n",
    "X_real = X[X.columns[(X.dtypes==\"float64\")]].fillna(0)\n",
    "X_real.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UniqueCarrier', 'Origin', 'Dest'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# заменим пропуски на \"0\" в вещественных признаках\n",
    "X = X.fillna(0)\n",
    "\n",
    "# обратим внимание на категориальные признаки\n",
    "X.columns[(X.dtypes==\"object\").values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "def transform_data(data):\n",
    "    #one-hot, так же удалим изначальный столбец drop_first=True\n",
    "    X_dum = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "    #масштабирование признаков\n",
    "    stander = StandardScaler()\n",
    "    X_stand = stander.fit_transform(X_dum)\n",
    "    X = pd.DataFrame(data=X_stand)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените функцию transform_data к данным. Сколько признаков получилось после преобразования?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transform_data(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>624</th>\n",
       "      <th>625</th>\n",
       "      <th>626</th>\n",
       "      <th>627</th>\n",
       "      <th>628</th>\n",
       "      <th>629</th>\n",
       "      <th>630</th>\n",
       "      <th>631</th>\n",
       "      <th>632</th>\n",
       "      <th>633</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.111232</td>\n",
       "      <td>0.256159</td>\n",
       "      <td>-0.463891</td>\n",
       "      <td>-1.004665</td>\n",
       "      <td>-0.805728</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>-0.738324</td>\n",
       "      <td>-0.143429</td>\n",
       "      <td>-0.049486</td>\n",
       "      <td>1.627386</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015586</td>\n",
       "      <td>-0.044926</td>\n",
       "      <td>-0.011953</td>\n",
       "      <td>-0.03072</td>\n",
       "      <td>-0.01134</td>\n",
       "      <td>-0.00756</td>\n",
       "      <td>-0.045402</td>\n",
       "      <td>-0.014144</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>-0.021718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.111232</td>\n",
       "      <td>-1.332282</td>\n",
       "      <td>-0.463891</td>\n",
       "      <td>0.084156</td>\n",
       "      <td>0.096865</td>\n",
       "      <td>-0.157504</td>\n",
       "      <td>0.193626</td>\n",
       "      <td>-0.143429</td>\n",
       "      <td>-0.049486</td>\n",
       "      <td>0.246361</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015586</td>\n",
       "      <td>-0.044926</td>\n",
       "      <td>-0.011953</td>\n",
       "      <td>-0.03072</td>\n",
       "      <td>-0.01134</td>\n",
       "      <td>-0.00756</td>\n",
       "      <td>-0.045402</td>\n",
       "      <td>-0.014144</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>-0.021718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.473737</td>\n",
       "      <td>-1.445742</td>\n",
       "      <td>1.540176</td>\n",
       "      <td>-0.227008</td>\n",
       "      <td>0.344350</td>\n",
       "      <td>-0.717701</td>\n",
       "      <td>0.481876</td>\n",
       "      <td>-0.143429</td>\n",
       "      <td>-0.049486</td>\n",
       "      <td>-0.345507</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015586</td>\n",
       "      <td>-0.044926</td>\n",
       "      <td>-0.011953</td>\n",
       "      <td>-0.03072</td>\n",
       "      <td>-0.01134</td>\n",
       "      <td>-0.00756</td>\n",
       "      <td>-0.045402</td>\n",
       "      <td>-0.014144</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>-0.021718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.573653</td>\n",
       "      <td>0.823459</td>\n",
       "      <td>-0.463891</td>\n",
       "      <td>0.808339</td>\n",
       "      <td>-0.325316</td>\n",
       "      <td>-0.530969</td>\n",
       "      <td>-0.340433</td>\n",
       "      <td>-0.143429</td>\n",
       "      <td>-0.049486</td>\n",
       "      <td>-0.345507</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015586</td>\n",
       "      <td>-0.044926</td>\n",
       "      <td>-0.011953</td>\n",
       "      <td>-0.03072</td>\n",
       "      <td>-0.01134</td>\n",
       "      <td>-0.00756</td>\n",
       "      <td>-0.045402</td>\n",
       "      <td>-0.014144</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>-0.021718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.403716</td>\n",
       "      <td>-1.332282</td>\n",
       "      <td>1.540176</td>\n",
       "      <td>-0.924709</td>\n",
       "      <td>0.504488</td>\n",
       "      <td>-0.664349</td>\n",
       "      <td>0.646338</td>\n",
       "      <td>-0.143429</td>\n",
       "      <td>-0.049486</td>\n",
       "      <td>-0.937375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015586</td>\n",
       "      <td>-0.044926</td>\n",
       "      <td>-0.011953</td>\n",
       "      <td>-0.03072</td>\n",
       "      <td>-0.01134</td>\n",
       "      <td>-0.00756</td>\n",
       "      <td>-0.045402</td>\n",
       "      <td>-0.014144</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>-0.021718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 634 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.111232  0.256159 -0.463891 -1.004665 -0.805728  0.002552 -0.738324   \n",
       "1 -0.111232 -1.332282 -0.463891  0.084156  0.096865 -0.157504  0.193626   \n",
       "2  0.473737 -1.445742  1.540176 -0.227008  0.344350 -0.717701  0.481876   \n",
       "3 -1.573653  0.823459 -0.463891  0.808339 -0.325316 -0.530969 -0.340433   \n",
       "4 -0.403716 -1.332282  1.540176 -0.924709  0.504488 -0.664349  0.646338   \n",
       "\n",
       "        7         8         9    ...       624       625       626      627  \\\n",
       "0 -0.143429 -0.049486  1.627386  ... -0.015586 -0.044926 -0.011953 -0.03072   \n",
       "1 -0.143429 -0.049486  0.246361  ... -0.015586 -0.044926 -0.011953 -0.03072   \n",
       "2 -0.143429 -0.049486 -0.345507  ... -0.015586 -0.044926 -0.011953 -0.03072   \n",
       "3 -0.143429 -0.049486 -0.345507  ... -0.015586 -0.044926 -0.011953 -0.03072   \n",
       "4 -0.143429 -0.049486 -0.937375  ... -0.015586 -0.044926 -0.011953 -0.03072   \n",
       "\n",
       "       628      629       630       631       632       633  \n",
       "0 -0.01134 -0.00756 -0.045402 -0.014144 -0.010001 -0.021718  \n",
       "1 -0.01134 -0.00756 -0.045402 -0.014144 -0.010001 -0.021718  \n",
       "2 -0.01134 -0.00756 -0.045402 -0.014144 -0.010001 -0.021718  \n",
       "3 -0.01134 -0.00756 -0.045402 -0.014144 -0.010001 -0.021718  \n",
       "4 -0.01134 -0.00756 -0.045402 -0.014144 -0.010001 -0.021718  \n",
       "\n",
       "[5 rows x 634 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**16. (0.5 балла)** Разбейте выборку и вектор целевой переменной на обучение и контроль в отношении 70/30 (для этого можно использовать, например, функцию [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn\n",
    "\n",
    "<img src = \"https://pp.vk.me/c4534/u35727827/93547647/x_d31c4463.jpg\">\n",
    "Теперь, когда мы привели данные к пригодному виду, попробуем решить задачу при помощи метода наименьших квадратов. Напомним, что данный метод заключается в оптимизации функционала $MSE$:\n",
    "\n",
    "$$MSE(X, y) = \\frac{1}{l} \\sum_{i=1}^l (<w, x_i> - y_i)^2 \\to \\min_{w},$$\n",
    "\n",
    "где $\\{ (x_i, y_i ) \\}_{i=1}^l$ — обучающая выборка, состоящая из $l$ пар объект-ответ.\n",
    "\n",
    "Заметим, что решение данной задачи уже реализовано в модуле sklearn в виде класса [LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression).\n",
    "\n",
    "**17.** Обучите линейную регрессию на 1000 объектах из обучающей выборки и выведите значения $MSE$ и $R^2$ на этой подвыборке и контрольной выборке (итого 4 различных числа). Проинтерпретируйте полученный результат — насколько качественные прогнозы строит полученная модель? Какие проблемы наблюдаются в модели?\n",
    "\n",
    "**Подсказка**: изучите значения полученных коэффициентов $w$, сохраненных в атрибуте coef_ объекта LinearRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for test: -9.043693437966633e+26 \n",
      "\n",
      " R2 for train: 0.9569387342023659 \n",
      "\n",
      " MSE for test: 1.1359157730055437e+30 \n",
      "\n",
      " MSE for train: 43.119784872818215\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "# model fiting w coef\n",
    "lr = LinearRegression()\n",
    "lr_model = lr.fit(x_train.iloc[:1000], y_train.iloc[:1000])\n",
    "\n",
    "# predict y-values for test and train dataset\n",
    "y_test_predict =lr_model.predict(x_test)\n",
    "y_train_predict = lr_model.predict(x_train.iloc[:1000])\n",
    "\n",
    "# r2 scores for model (estimation)\n",
    "r2_test = r2_score(y_test, y_test_predict)\n",
    "r2_train = r2_score(y_train.iloc[:1000], y_train_predict)\n",
    "\n",
    "# mse score for model (estimation)\n",
    "mse_test = mean_squared_error(y_test, y_test_predict)\n",
    "mse_train = mean_squared_error(y_train.iloc[:1000], y_train_predict)\n",
    "\n",
    "\n",
    "print(\"R2 for test: {} \\n\\n R2 for train: {} \\n\\n MSE for test: {} \\n\\n MSE for train: {}\".format(r2_test, r2_train, mse_test, mse_train) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ениваете свою оценку по невидимым данным, что может привести к результатам вне [0,1]. модель еще хуже, чем предполагаемая наихудшая модель  Это может возникнуть, когда прогнозы, которые сравниваются с соответствующими результатами, не были получены из процедуры подгонки модели с использованием этих данных. Даже если была использована процедура подгонки модели, R2 все равно может быть отрицательным, например, когда линейная регрессия проводится без включения перехвата или когда для подгонки данных используется нелинейная функция. В тех случаях, когда возникают отрицательные значения, среднее значение данных обеспечивает лучшее соответствие результатам, чем соответствующие значения функций, в соответствии с этим конкретным критерием/ среднее значение вашего тестового набора сильно отличается от среднего вашего набора тренировок. Это само по себе может вызвать гораздо более высокую поведенческую ошибку в вашем прогнозе, чем просто предсказать среднее значение тестовых данных, что приводит к отрицательной оценке r^2.\n",
    "\n",
    "В худшем случае, если ваши данные вообще не объясняют вашу цель, эти баллы могут стать очень сильно отрицательными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Для решения описанных вами в предыдущем пункте проблем используем L1- или L2-регуляризацию, тем самым получив Lasso и Ridge регрессии соответственно и изменив оптимизационную задачу одним из следующих образов:\n",
    "$$MSE_{L1}(X, y) = \\frac{1}{l} \\sum_{i=1}^l (<w, x_i> - y_i)^2 + \\alpha ||w||_1 \\to \\min_{w},$$\n",
    "$$MSE_{L2}(X, y) = \\frac{1}{l} \\sum_{i=1}^l (<w, x_i> - y_i)^2 + \\alpha ||w||_2^2 \\to \\min_{w},$$\n",
    "\n",
    "где $\\alpha$ — коэффициент регуляризации. Один из способов его подбора заключается в переборе некоторого количества значений и оценке качества на кросс-валидации для каждого из них, после чего выбирается значение, для которого было получено наилучшее качество.\n",
    "\n",
    "**18.** Обучите линейные регрессии с L1- и L2-регуляризатором, подобрав лучшее значение параметра регуляризации из списка alpha_grid при помощи кросс-валидации c 5 фолдами на тех же 1000 объектах, что и в п.17. Выведите значения $MSE$ и $R^2$ на обучающей и контрольной выборках. Удалось ли решить указанные вами ранее проблемы?\n",
    "\n",
    "Для выполнения данного задания вам могут понадобиться реализованные в библиотеке объекты [LassoCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html), [RidgeCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html) и [KFold](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 594.2053206847177, tolerance: 61.90742161649644\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 374.17111295105315, tolerance: 72.10848521922168\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1084.529135054141, tolerance: 41.05422634612183\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 210.33608853676924, tolerance: 70.98701047190326\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 620.3088346377699, tolerance: 71.12716603884108\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 501.7810798635237, tolerance: 64.38420748543422\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 79.79892947970984, tolerance: 72.19571921853742\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 86.74553546300012, tolerance: 43.66294031339524\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 349.32344394335087, tolerance: 72.12688627405551\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 136.22732221212755, tolerance: 71.91464070320963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 70.84008746569998, tolerance: 51.69979416278018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 91.11358402790938, tolerance: 81.3750682844252\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 221.91832357894236, tolerance: 43.57361232840297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1087.3469128824017, tolerance: 43.36335185696306\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 83.41975878052472, tolerance: 52.55847803001928\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 59.07594985119067, tolerance: 51.85953420067889\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1255.5226265554993, tolerance: 52.886815748978755\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 196.87490044309743, tolerance: 61.078486237550415\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 397.2254920908199, tolerance: 71.16473527383425\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 104.74711754656892, tolerance: 70.95397574874559\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 83.38064286080407, tolerance: 75.31087287373153\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1233.696386744341, tolerance: 57.01022557498466\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 471.3791518301405, tolerance: 79.31888947385711\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 553.7440391169512, tolerance: 61.078486237550415\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92.31236503842229, tolerance: 88.65491864371315\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for KFold Ridge: [0.9260746  0.91207205 0.83715167 0.94405083 0.88474608] \n",
      " R2_for KFold Lasoo:[0.89700805 0.91273939 0.85389618 0.94380948 0.90483719] \n",
      "\n",
      "\n",
      "Best ridge alpha: 0.1 \n",
      " MSE for RidgeTest: 66.00853706750851 \n",
      " MSE for RidgeTrain: 32.034919505610915 \n",
      " R2 for Ridgetest: 0.9474467220445674 \n",
      " R2 for Ridgetrain: 0.9680085559864073 \n",
      "\n",
      "\n",
      "\n",
      "Best lasso alpha: 0.001 \n",
      " MSE for LassoTest: 65.86775787221688 \n",
      " MSE for LassoTrain: 32.01384943842093 \n",
      " R2 for Lassotest: 0.9475588046403828 \n",
      " R2 for Lassotrain: 0.9680295974588153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\_username_\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 354.4312650254142, tolerance: 100.13589724802584\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "\n",
    "x_train = x_train.iloc[:1000]\n",
    "y_train = y_train.iloc[:1000]\n",
    "\n",
    "kfold = KFold(n_splits=5).split(x_train)\n",
    "\n",
    "ridge_regression = RidgeCV(alphas=[0.001, 0.1, 1, 10])\n",
    "lasso_regression = LassoCV(alphas=[0.001, 0.1])\n",
    "\n",
    "#kfold for l1 l2 model\n",
    "score_ridge = cross_val_score(ridge_regression, x_train, y_train, scoring=\"r2\", cv=5)\n",
    "score_lasso = cross_val_score(lasso_regression, x_train, y_train, scoring=\"r2\", cv=5)\n",
    "\n",
    "#fiting model ridge L2-reg    \n",
    "ridge_model = ridge_regression.fit(x_train, y_train)\n",
    "\n",
    "#fiting model lasso L1-reg \n",
    "lasso_model = lasso_regression.fit(x_train, y_train)\n",
    "\n",
    "# predict y-values ridge\n",
    "y_train_predict = ridge_model.predict(x_train)\n",
    "y_test_predict = ridge_model.predict(x_test)\n",
    "\n",
    "#r2 score for model ridge\n",
    "r2_train = r2_score(y_train, y_train_predict)\n",
    "r2_test = r2_score(y_test, y_test_predict)\n",
    "\n",
    "#mse score for model ridge\n",
    "mse_train = mean_squared_error(y_train, y_train_predict)\n",
    "mse_test = mean_squared_error(y_test, y_test_predict)\n",
    "\n",
    "\n",
    "# predict y-values lasso\n",
    "y_train_predict_lasso = lasso_model.predict(x_train)\n",
    "y_test_predict_lasso = lasso_model.predict(x_test)\n",
    "\n",
    "#r2 score for model lasso\n",
    "r2_train_lasso = r2_score(y_train, y_train_predict_lasso)\n",
    "r2_test_lasso = r2_score(y_test, y_test_predict_lasso)\n",
    "\n",
    "#mse score for model lasso\n",
    "mse_train_lasso = mean_squared_error(y_train, y_train_predict_lasso)\n",
    "mse_test_lasso = mean_squared_error(y_test, y_test_predict_lasso)\n",
    "\n",
    "\n",
    "print(\"R2 for KFold Ridge: {} \\n R2_for KFold Lasoo:{} \\n\\n\".format(score_ridge, score_lasso))\n",
    "print(\"Best ridge alpha: {} \\n MSE for RidgeTest: {} \\n MSE for RidgeTrain: {} \\n R2 for Ridgetest: {} \\n R2 for Ridgetrain: {} \\n\\n\\n\".format(ridge_model.alpha_, mse_test, mse_train, r2_test, r2_train ))\n",
    "print(\"Best lasso alpha: {} \\n MSE for LassoTest: {} \\n MSE for LassoTrain: {} \\n R2 for Lassotest: {} \\n R2 for Lassotrain: {}\".format(lasso_model.alpha_, mse_test_lasso, mse_train_lasso, r2_test_lasso, r2_train_lasso ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалось ли решить указанные вами ранее проблемы? Да результаты лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный спуск\n",
    "\n",
    "В предыдущем разделе мы использовали существующие реализации методов обучения линейной регрессии с регуляризацией и без. Тем не менее, подобные реализации, как правило, имеются лишь для ограниченного набора стандартных методов. В частности, при выходе функционала качества за пределы стандартного множества необходимо самостоятельно реализовывать составляющие процесса решения оптимизационной задачи. Именно этому и посвящен данный раздел задания.\n",
    "\n",
    "Пусть необходимо минимизировать следующий функционал (Mean Square Percentage Error — модифицированный [RMSPE](https://www.kaggle.com/c/rossmann-store-sales/details/evaluation)):\n",
    "$$MSPE(\\{x_i, y_i\\}_{i=1}^l, \\, w) = \\frac{1}{l}\\sum_{i=1}^l \\left( \\frac{y_i - \\langle w, x_i \\rangle }{y_i} \\right)^2,$$\n",
    "\n",
    "где $\\{x_i, y_i\\}_{i=1}^l$ — обучающая выборка, $w$ — вектор весов линейной модели. Будем также рассматривать функционал $MSPE$ с L2-регуляризацией:\n",
    "\n",
    "$$MSPE(\\{x_i, y_i\\}_{i=1}^l, \\, w) = \\frac{1}{l}\\sum_{i=1}^l \\left( \\frac{y_i - \\langle w, x_i \\rangle }{y_i} \\right)^2 + ||w||_2^2.$$\n",
    "\n",
    "$$\n",
    "\\textrm{RMSPE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} \\left(\\frac{y_i - \\hat{y}_i}{y_i}\\right)^2},\n",
    "$$\n",
    "\n",
    "**19.** Добавьте к объектам обеих выборок из п. 16 единичный признак.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-d0f23a277692>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_test[635] = 1\n"
     ]
    }
   ],
   "source": [
    "x_train[635] = 1\n",
    "x_test[635] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**20.** Реализуйте функции, которые вычисляют:\n",
    " * прогнозы линейной модели;\n",
    " * функционал $MSPE$ и его градиент;\n",
    " * регуляризованный $MSPE$ и его градиент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class LossAndDerivatives:\n",
    "    @staticmethod\n",
    "    def mse(X, Y, w):\n",
    "\n",
    "        return np.mean((X.dot(w) - Y)**2)\n",
    "\n",
    "    @staticmethod\n",
    "    def mae(X, Y, w):\n",
    "\n",
    "        # YOUR CODE HERE    \n",
    "        return np.mean(abs(X.dot(w) - Y))\n",
    "\n",
    "    @staticmethod\n",
    "    def l2_reg(w):\n",
    "        \n",
    "        return  np.sum(w**2)\n",
    "\n",
    "    @staticmethod\n",
    "    def l1_reg(w):\n",
    "        \n",
    "        return np.sum(abs(w))\n",
    "    \n",
    "    @staticmethod\n",
    "    def mse_derivative(X, Y, w):\n",
    "\n",
    "        return  np.mean(X.T.dot((Y - X.dot(w)))) * 2\n",
    "\n",
    "    @staticmethod\n",
    "    def mae_derivative(X, Y, w):\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        return \n",
    "\n",
    "    @staticmethod\n",
    "    def l2_reg_derivative(w):\n",
    "\n",
    "        \n",
    "        return np.sum(2 * w)\n",
    "\n",
    "    @staticmethod\n",
    "    def l1_reg_derivative(w):\n",
    "\n",
    "        return np.ones_like(w)\n",
    "    \n",
    "    @staticmethod\n",
    "    def no_reg(w):\n",
    "\n",
    "        return 0.\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def no_reg_derivative(w):\n",
    "\n",
    "        return np.zeros_like(w)\n",
    "        \n",
    "    @staticmethod\n",
    "    def mpse(X, y, w):\n",
    "        pred = X.dot(w)\n",
    "        ans = np.mean( ( (pred - (y + np.random.normal(1e-9)) ) / (y + np.random.normal(1e-9)) ) **2 ) \n",
    "        return ans\n",
    "\n",
    "    @staticmethod\n",
    "    def mpse_derivative(X, y, w):\n",
    "        pred = X.dot(w)\n",
    "        return ( ( ((pred - y) / (y + np.random.normal(1e-9)) / (y + np.random.normal(1e-9))).dot(X) ) * 2 ) / X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**21.** Реализуйте метод градиентного спуска для описанных функционалов ($MSPE$ и его регуляризованный вариант). Функция должна принимать следующие параметры:\n",
    " - X — матрица \"объект-признак\";\n",
    " - y — вектор целевой переменной;\n",
    " - w0 — начальное значение вектора весов;\n",
    " - step_size — значение темпа обучения;\n",
    " - max_iter — максимальное число итераций;\n",
    " - eps — значение, используемое в критерии останова;\n",
    " - is_reg — бинарный параметр, принимает значение True в случае наличия регуляризации функционала, False — в противном случае.\n",
    " \n",
    "Процесс должен быть остановлен, если выполнено хотя бы одно из следующих условий:\n",
    " - было выполнено заданное количество итераций max_iter;\n",
    " - евклидова норма разности векторов $w$ на соседних итерациях стала меньше, чем eps.\n",
    "\n",
    "Функция должна возвращать полученный в результате оптимизации вектор $w$ и список значений функционала на каждой итерации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w_by_grad(X, Y, w_0, lr, loss_mode='mse', reg_mode=None,  n_steps=100, reg_coeff=0.05):\n",
    "    if loss_mode == 'mse':\n",
    "        loss_function = LossAndDerivatives.mse\n",
    "        loss_derivative = LossAndDerivatives.mse_derivative\n",
    "    elif loss_mode == 'mae':\n",
    "        loss_function = LossAndDerivatives.mae\n",
    "        loss_derivative = LossAndDerivatives.mae_derivative\n",
    "    elif loss_mode == \"mpse\":\n",
    "        loss_function = LossAndDerivatives.mpse\n",
    "        loss_derivative = LossAndDerivatives.mpse_derivative\n",
    "    else:\n",
    "        raise ValueError('Unknown loss function. Available loss functions: `mse`, `mae`')\n",
    "    \n",
    "    if reg_mode is None:\n",
    "        reg_function = LossAndDerivatives.no_reg\n",
    "        reg_derivative = LossAndDerivatives.no_reg_derivative # lambda w: np.zeros_like(w)\n",
    "    elif reg_mode == 'l2':\n",
    "        reg_function = LossAndDerivatives.l2_reg\n",
    "        reg_derivative = LossAndDerivatives.l2_reg_derivative\n",
    "    elif reg_mode == 'l1':\n",
    "        reg_function = LossAndDerivatives.l1_reg\n",
    "        reg_derivative = LossAndDerivatives.l1_reg_derivative\n",
    "    else:\n",
    "        raise ValueError('Unknown regularization mode. Available modes: `l1`, `l2`, None')\n",
    "    \n",
    "    \n",
    "    w = w_0.copy()\n",
    "    hist_loss = []\n",
    "    for i in range(n_steps):\n",
    "        empirical_risk = loss_function(X, Y, w) + reg_coeff * reg_function(w)\n",
    "        gradient = loss_derivative(X, Y, w) + reg_coeff * reg_derivative(w)\n",
    "        gradient_norm = np.linalg.norm(gradient)\n",
    "        hist_loss.append(empirical_risk)\n",
    "        \n",
    "        if gradient_norm > 5.:\n",
    "            gradient = gradient / gradient_norm * 5.\n",
    "        w -= lr * gradient\n",
    "        \n",
    "        #if i % 25 == 0:\n",
    "            #print('Step={}, loss={},\\ngradient values={}\\n'.format(i, empirical_risk, gradient))\n",
    "    return w, hist_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите линейную регрессию с функционалом $MSPE$ на обучающей выборке при помощи метода градиентного спуска и изобразите кривые зависимости значения функционала от номера итерации для различных:\n",
    " * значений размера шага из набора [0.001, 1, 10];\n",
    " * способов начальной инициализации вектора весов (нули, случайные веса).\n",
    "\n",
    "Проанализируйте полученные результаты — влияют ли данные параметры на скорость сходимости и итоговое качество? Если да, то как?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step_size:  0.001\n",
      "loss_mpse: 1.528224601515296\n",
      "Step_size:  1\n",
      "loss_mpse: 1.330819135451833\n",
      "Step_size:  10\n",
      "loss_mpse: 951.6259775693156\n"
     ]
    }
   ],
   "source": [
    "# градиентный спуск mpse(не регуляризованный) инициализации вектора весов (нули)\n",
    "for lr in [0.001, 1 , 10]:\n",
    "    print(\"Step_size: \", lr)\n",
    "    w0 = np.zeros(x_train.shape[1])\n",
    "    ww, hist_loss1 = get_w_by_grad(x_train /100, y_train, w0, lr, loss_mode='mpse', reg_mode=None,n_steps=50, reg_coeff=0.05)\n",
    "    \n",
    "    if lr == 0.001:\n",
    "        pred_plot1 = hist_loss1.copy()\n",
    "    print(\"loss_mpse:\",hist_loss1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step_size:  0.001\n",
      "loss_mpse: 1.4979902968665337\n",
      "Step_size:  1\n",
      "loss_mpse: 1.292976282713541\n",
      "Step_size:  10\n",
      "loss_mpse: 4.874748364595262\n"
     ]
    }
   ],
   "source": [
    "# градиентный спуcк mpse (не регуляризованный) нициализации вектора весов (случайные веса)\n",
    "for lr in [0.001, 1 , 10]:\n",
    "    print(\"Step_size: \", lr)\n",
    "    w0 = np.random.rand( x_train.shape[1])\n",
    "    ww, hist_loss2 = get_w_by_grad(x_train / 100, y_train, w0, lr, loss_mode='mpse', reg_mode=None,  n_steps=50, reg_coeff=0.05)\n",
    "\n",
    "    if lr == 0.001:\n",
    "        pred_plot2 = hist_loss2.copy()\n",
    "    print(\"loss_mpse:\",hist_loss2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(np.arange(len(pred_plot1)),pred_plot1, label=\"zero_step_0.001\")\n",
    "plt.plot(np.arange(len(pred_plot2)),pred_plot2, label=\"random_step_0.001\")  \n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.ylim([0, 200])\n",
    "plt.xlim([0, 40])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**22.** Обучите линейную регрессию с функционалом MSPE и его регуляризованным вариантом на обучающей выборке при помощи метода градиентного спуска и изобразите кривые зависимости значения функционала от номера итерации. Исследуйте зависимость скорости сходимости от наличия регуляризации. Обоснуйте, почему так происходит."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ОТВЕТ:__ Число обусловленности матрицы X существенно влияет на скорость сходимости градиентного спуска: чем более вытянуты линии уровня функции потерь, тем хуже\n",
    "\n",
    "Темп обучения α тоже сильно влияет на поведение градиентного спуска; вообще говоря, он является гиперпараметром алгоритма, и его, возможно, придётся подбирать отдельно. Другими гиперпараметрами являются максимальное число итераций S и/или порог tolerance\n",
    "\n",
    "решение может быть не уникальным и сколь угодно большим по модулю, что создаёт вычислительные трудности (малые погрешности признаков сильно возрастают при предсказании ответа, а в градиентном спуске накапливается погрешность из-за операций со слишком большими числами).\n",
    "\n",
    " редко бывает так, что признаки строго линейно зависимы, а вот быть приближённо линейно зависимыми они вполне могут быть (такая ситуация называется мультиколлинеарностью).\n",
    " \n",
    " В случае, когда несколько признаков «почти» линейно независимы, веса  𝑤𝑖  при них теряют физический смысл. Может даже оказаться, что вес признака, с ростом которого таргет, казалось бы, должен увеличиваться, станет отрицательным. Это делает модель не только неточной, но и принципиально не интерпретируемой. Вообще, неадекватность знаков или величины весов – хорошее указание на мультиколлинеарность.\n",
    "\n",
    "Для того, чтобы справиться с этой проблемой, задачу обычно регуляризуют, то есть добавляют к ней дополнительное ограничение на величину вектора весов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = np.random.rand( x_train.shape[1])\n",
    "ww, hist_loss1 = get_w_by_grad(x_train/100, y_train, w0, lr=0.005, loss_mode='mpse', reg_mode=None,n_steps=50, reg_coeff=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = np.random.rand( x_train.shape[1])\n",
    "ww, hist_loss_l2 = get_w_by_grad(x_train/100, y_train, w0, lr=0.005, loss_mode='mpse', reg_mode=\"l2\",n_steps=50, reg_coeff=0.005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(hist_loss1)),hist_loss1, label=\"random_step_0.005\")\n",
    "plt.plot(np.arange(len(hist_loss_l2)),hist_loss_l2, label=\"reg_random__step_0.005\")  \n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.ylim([0, 250])\n",
    "plt.xlim([0, 40])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод градиентного спуска может быть весьма трудозатратен в случае большого размера обучающей выборки. Поэтому часто используют метод стохастического градиентного спуска, где на каждой итерации выбирается случайный объект из обучающей выборки и обновление весов происходит только по этому объекту. \n",
    "\n",
    "**23.**  Реализуйте метод стохастического градиентного спуска (SGD) для описанных функционалов ($MSPE$ и его регуляризованный вариант). Функция должна иметь параметры и возвращаемое значение, аналогичные оным функции grad\\_descent из п.21. Кроме того, должен использоваться аналогичный критерий останова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возвращает вектор прогнозов линейной модели с вектором весов w для выборки X\n",
    "def make_pred(X, w):\n",
    "    return X.dot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# возвращает значение функционала MSPE для выборки (X, y) и вектора весов w\n",
    "def get_func_mspe(w, X, y):\n",
    "    \n",
    "    # добавим к y шум, чтобы не делить на ноль\n",
    "    pred = X.dot(w)\n",
    "    ans = np.mean( ( (pred - y ) / (y + np.random.normal(1e-7)) ) **2 ) \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возвращает градиент функционала MSPE для выборки (X, y) и вектора весов w\n",
    "def get_grad(w, X, y):\n",
    "    pred = X.dot(w)\n",
    "    return ( ( ((pred - y) / (y + np.random.normal(1e-7)) / (y + np.random.normal(1e-7))).dot(X) ) * 2 ) / X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возвращает значение регуляризованного функционала MSPE для выборки (X, y) и вектора весов w\n",
    "def get_reg_func(w, X, y):\n",
    "    pred = X.dot(w)\n",
    "    \n",
    "    \n",
    "    #l1 = np.mean( np.true_divide( (X.dot(w) - Y), X.dot(w)) **2 ) + np.sum(abs(w))\n",
    "    l = np.mean( ( (pred - y ) / (y + np.random.normal(1e-7)) ) **2 )  + np.sum(w * 0.5) \n",
    "    \n",
    "    return l\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возвращает градиент регуляризованного функционала MSPE для выборки (X, y) и вектора весов w\n",
    "def get_reg_grad(w, X, y):\n",
    "    pred = X.dot(w)\n",
    "    return (( (X.T.dot((pred - y) / (y + np.random.normal(1e-7)) ** 2 )) ) * 2 ) / X.shape[0]  + (2 * w / X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(X, y, w0, step_size_0, max_iter, eps, is_reg):\n",
    "    \n",
    "    w = w0.copy()\n",
    "    iterat = 0\n",
    "    w_list = list([w])\n",
    "    history_pred = []\n",
    "    \n",
    "    if is_reg == True:\n",
    "        \n",
    "        gradient = get_reg_grad\n",
    "        func = get_reg_func\n",
    "   \n",
    "    else:\n",
    "        \n",
    "        gradient = get_grad\n",
    "        func = get_func_mspe\n",
    "         \n",
    "    while iterat < max_iter :\n",
    "        \n",
    "        for indx in np.random.choice(X.shape[0] - 1, 5):\n",
    "    \n",
    "            iterat += 1\n",
    "            step_size = step_size_0 / ((iterat+1)**0.51)\n",
    "\n",
    "            #отбираем батч\n",
    "            X_batch = X.iloc[:indx]\n",
    "            Y_batch = y.iloc[:indx]\n",
    "\n",
    "            #ошибка и значение\n",
    "            predict = func(w, X_batch, Y_batch)\n",
    "            history_pred.append(predict)\n",
    "\n",
    "            # посчитать градиент\n",
    "            grad = gradient(w, X_batch, Y_batch)\n",
    "\n",
    "            #обновить веса\n",
    "            w_pre = w.copy()\n",
    "            w = w - step_size * grad\n",
    "            w_list.append(w)\n",
    "\n",
    "            # расчет евклидовой нормы между соседними векторами\n",
    "            dist = np.linalg.norm( w_pre - w)\n",
    "        \n",
    "\n",
    "        #print(\"Проход:{}, вес:  \\n\\n Евклид:{}\\n\\n MSPE:{} \\n\\n\".format(iterat, dist, predict))\n",
    "        \n",
    "        #if dist < eps or predict > 10000:\n",
    "            \n",
    "            #print(\"Выполнилось условие остановки  \\n\\n\")\n",
    "            #break\n",
    "        #else:\n",
    "            #continue\n",
    "     \n",
    "    return  w, history_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите линейную регрессию с функционалом $MSPE$ и его регуляризованным вариантом на обучающей выборке при помощи метода стохастического градиентного спуска, подобрав при этом размер шага, при котором метод будет сходиться. Нарисуйте график сходимости. Выведите значения $MSPE, MSE, R^2$ на контрольной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = np.random.rand( x_train.shape[1])\n",
    "w, pred_sgd = sgd(x_train, y_train, w0, 0.0001, 40, 1e-3, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = np.random.rand( x_train.shape[1])\n",
    "w, pred_reg_sgd = grad_descent(x_train, y_train, w0, 0.0001, 40, 1e-2, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(pred_sgd)),pred_sgd, label=\"sgd_random_step_0.0001\")\n",
    "plt.plot(np.arange(len(pred_reg_sgd)),pred_reg_sgd, label=\"sgd_reg_random_step_0.0001\")  \n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.ylim([0, 5000])\n",
    "plt.xlim([0, 40])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for test: 1397.2030513628397\n",
      "MPSE for test:2300.3130925348282\n",
      "R2 score: -11.248179985977226\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"MSE for test: {}\".format(mean_squared_error(make_pred(x_test,w), y_test)))\n",
    "print(\"MPSE for test:{}\".format(get_func_mspe(w, x_test, y_test)))\n",
    "print(\"R2 score: {}\".format(r2_score(make_pred( x_test, w), y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**24.** Аналогично п.22 исследуйте зависимость скорости сходимости метода SGD от наличия регуляризации. Обоснуйте, почему так происходит."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__ОТВЕТ:__ \n",
    "Шаги стохастического градиентного спуска заметно более шумные, но их значительно быстрее считать. И в итоге они тоже сходятся к оптимальному значению (ппо крайней мере для хорошо подобранных коэффициентов темпа обучения в случае выпуклого функционала качества) из-за того, что матожидание оценки градиента на батче равно самому градиенту.\n",
    "    \n",
    "  Для сложных моделей и лоссов стохастический градиентный спуск может сходиться плохо или застревать в локальных минимумах, поэтому придумано множество его улучшений, о которых можно будет узнать в главе про методы оптимизации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**25.** Обучите стандартную линейную регрессию с функционалом качества MSE на обучающей выборке и выведите значение MSPE полученного решения на контрольной выборке. Как оно соотносится с аналогичным результатом для решения, полученного в п.22? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# возвращает значение функционала MSPE для выборки (X, y) и вектора весов w\n",
    "def get_func_mspe(w, X, y):\n",
    "    \n",
    "    # добавим к y шум, чтобы не делить на ноль\n",
    "    pred = X.dot(w)\n",
    "    ans = np.mean( ( (pred - y ) / (y + np.random.normal(1e-7)) ) **2 ) \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MSPE for test:1.0869957064532028e+30 \n",
      " MSPE for train:3.033109690072993e+26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "# model fiting w coef\n",
    "lr = LinearRegression()\n",
    "lr_model = lr.fit(x_train.iloc[:1000], y_train.iloc[:1000])\n",
    "\n",
    "# mspe score\n",
    "mspe_test = get_func_mspe(lr_model.coef_, x_test, y_test )\n",
    "mspe_train = get_func_mspe(lr_model.coef_, x_train, y_train )\n",
    "\n",
    "print(\" MSPE for test:{} \\n MSPE for train:{}\".format(mspe_test, mspe_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ОТВЕТ:__\n",
    "Самописная MPSE for test:2300.3130925348282  точнее чем для линейной регрессии из коробки, т.к.инструмент LinearRegression из sklearn  решает оптимизационную задачу для mean squared error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
