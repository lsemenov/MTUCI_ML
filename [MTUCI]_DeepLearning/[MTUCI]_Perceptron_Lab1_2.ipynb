{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Технологии глубокого обучения и нейронных сетей, МТУСИ\n",
    "\n",
    "## Лабораторная работа 1: Обучение однослойного персептрона методом коррекции по ошибке через дельта-правило\n",
    "\n",
    "__Студент:__ Семенов А.И.\n",
    "\n",
    "__Группа:__ МБД2032"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Цель работы. \n",
    "\n",
    "    Изучить алгоритм обучения однослойного персептрона методом коррекции по ошибке через дельта-правило.\n",
    "\n",
    "\n",
    "### Задание\n",
    "\n",
    "    В соответствии с вариантом, необходимо обучить нейронную сеть распознавать указанные 4 символа. На каждый символ необходимо подготовить 4 обучающих образа с использованием разных шрифтов. Соответственно, всего будет 16 обучающих образов: 4 образа первым шрифтом, 4 образа, вторым шрифтом и т.д. Тестовая выборка должна содержать по 1 образу на каждый из 4-х символов. Символы должны быть написаны другим шрифтом, который не был использован в обучающей выборке. \n",
    "\n",
    "### Теоретические сведения\n",
    "\n",
    "    Обучение сети включает в себя передачу данных через сеть, использование функции потерь для определения разности между прогнозом и фактической маркировкой, а затем использование этой информации для обновления весов сети, чтобы возврат функции потерь был как можно меньше. Для выполнения обновлений в нейронной сети мы используем оптимизатор.\n",
    "\n",
    "        Ошибкой выхода персептрона:\n",
    "\n",
    "$$ e_j=d_j-y_j $$\n",
    "\n",
    "\n",
    "\n",
    "    Дельта-правило — метод обучения перцептрона по принципу градиентного спуска по поверхности ошибки. Его дальнейшее развитие привело к созданию метода обратного распространения ошибки.\n",
    "\n",
    "    Вес входного сигнала нейрона изменяется в сторону уменьшения ошибки пропорционально величине суммарной ошибки нейрона. Часто вводят коэффициент пропорциональности $\\eta$ , на который умножается величина ошибки. Этот коэффициент называют скоростью или нормой  обучения. \n",
    "    \n",
    "        Формула для корректировки весов:\n",
    "\n",
    "$$ w_{j}(t+1)=w_{j}(t)+\\eta * e_{j} *x_{j}, $$\n",
    "\n",
    "\n",
    "   где $\\eta$ -коэффициент пропорциональности(называют скоростью или нормой  обучения), \n",
    "\n",
    "   $e_{j}$ - величина ошибки "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Импорт библиотек\n",
    "2. Загрузчик данных и наборы данных\n",
    "3. Создание однослойной нейронной сети \n",
    "4. Уравнение для обучения\n",
    "5. Фцнкция потерь (коррекция по ошибке черех дельта правило )\n",
    "6. Оцениваем точность "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = './data/test'\n",
    "path_train = './data/train'\n",
    "\n",
    "transforms = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание загрузчика датасета "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(root = path_train, transform=transforms)\n",
    "test_dataset = ImageFolder(root = path_test, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset)\n",
    "test_loader = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 784)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = torch.flatten(i, start_dim=2, end_dim=3) ##сплющивание тензора 3,28,28 --> 3.784\n",
    "a = np.array(a)  ## меням тип на np.array\n",
    "a = np.squeeze(a )## убираем ось единичную - которая сообщает о батче\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Однослойный персептрон"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNet:\n",
    "    \n",
    "    \"\"\" \n",
    "    Нейронная сеть прямого распрастронения / классификатор \n",
    "    на основе многослойного персептрона\n",
    "    Параметры:\n",
    "    ---------\n",
    "    n_hidden : int (по умолчанию: 30)\n",
    "        количестов скрытых элементов\n",
    "    l2: float (по умолчанию: 0.)\n",
    "        значения лямбда для регулярщации L2\n",
    "        Регуляризация отстутствует, если l2=0 (принято по умолчанию).\n",
    "    epochs: int (по умолчанию: 100)\n",
    "        Количетсов проходов по обучающему набору.\n",
    "    lr: float (по умолчанию: 0.001)\n",
    "        скорость обучения \n",
    "    shuffle: bool (по умолчанию True)\n",
    "        Eсли True, тогда обучающие данные тасуются \n",
    "        каждую эпоху, чтобы предотвратить циклы\n",
    "    minibatch_size: int (по умолчанию 1)\n",
    "        Количество обучаюших образцов на минипакет\n",
    "    seed : int (по умолчанию:None)\n",
    "        Случайное начальное значение для инициализации весов и тасования\n",
    "        \n",
    "    Атрибуты:\n",
    "    --------\n",
    "    eval_ : dict\n",
    "        Словарь, в котором собираются показатели издержек,\n",
    "        правильности при обучении и правильности при испытании\n",
    "        для каждой эпохи во время обучения.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_features, num_labels,  num_classes, random_seed=123):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        # output layer инициализация весов для  слоя + баес\n",
    "        rgen = np.random.RandomState(random_seed)\n",
    "        \n",
    "        ### 784, 6\n",
    "        self.weight_o = rgen.normal(loc=0.0, scale=0.001, size=(  num_features, num_classes))\n",
    "        \n",
    "        ### 1,6\n",
    "        self.bias_o = np.zeros(num_classes)\n",
    "\n",
    "\n",
    "    def normalize(self, full_volume):\n",
    "        \"\"\"\n",
    "        Z-Normalization of the whole subject\n",
    "        \"\"\"\n",
    "        mu = full_volume.mean()\n",
    "        std = np.std(full_volume)\n",
    "        normalized = (full_volume - mu) / std\n",
    "        return normalized\n",
    "\n",
    "    def standardize(self, normalized_data):\n",
    "        \"\"\"\n",
    "        Standardize the normalized data into the 0-1 range\n",
    "        \"\"\"\n",
    "        standardized_data = (normalized_data - normalized_data.min()) / (normalized_data.max() - normalized_data.min())\n",
    "        return standardized_data\n",
    "\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1. / (1. + np.exp(-z))\n",
    "    \n",
    "    def int_to_onehot(self, y, num_labels):\n",
    "        \n",
    "        ''' \n",
    "        Кодирует метки класса в представление с унитарным кодом\n",
    "        \n",
    "        Параметры:\n",
    "        ---------\n",
    "        y: массив, форма = [n_examples]\n",
    "            Целеые значения.\n",
    "            \n",
    "        Возвращает:\n",
    "        ----------\n",
    "        onehot : массив, форма = (n_examples, n_labels)\n",
    "        '''\n",
    "        ## 1,6: [1,0,0,0,0,0] ---[0,1,0,0,0,0]\n",
    "        onehot = np.zeros((y.shape[0], num_labels))\n",
    "        for indx, val in enumerate(y):\n",
    "            onehot[indx, val] = 1\n",
    "\n",
    "        return onehot \n",
    "    \n",
    "    def forward(self, X):\n",
    "        \n",
    "        ## X: {3, 784}  *   weight_o: {784,6}  +  bias_o:{1,6}  = {3,6}\n",
    "        # 1 шаг прямого распространение скларяное произведение X и weight_h\n",
    "        z_out = np.dot(X, self.weight_o) + self.bias_o\n",
    "        \n",
    "        # превращает в меньше единицы\n",
    "        # 2 шаг применение функции активации (сигмоиды) - активация слоя\n",
    "        a_out = self.sigmoid(z_out)\n",
    "        \n",
    "        return  z_out, a_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(num_features = 28*28,\n",
    "                      num_labels=6,\n",
    "                      num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse_and_acc(nnet, X, y, num_labels=6 ):\n",
    "    mse, correct_pred, num_examples = 0., 0, 0\n",
    "\n",
    "\n",
    "    _, probas = nnet.forward(X)\n",
    "    predicted_labels = np.argmax(probas, axis=1)\n",
    "\n",
    "    onehot_targets = int_to_onehot(y, num_labels=num_labels)\n",
    "    loss = np.mean((onehot_targets - probas)**2)\n",
    "    correct_pred += (predicted_labels == y).sum()\n",
    "\n",
    "    num_examples += y.shape[0]\n",
    "    mse += loss\n",
    "\n",
    "    mse = mse\n",
    "    acc = correct_pred/num_examples\n",
    "    return mse, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, valid_loader,  num_epochs, learning_rate=0.1):\n",
    "    \n",
    "    \n",
    "    ''' \n",
    "    Обновляем веса \n",
    "    \n",
    "    '''\n",
    "    epoch_loss = []\n",
    "    _loss =[]\n",
    "    \n",
    "    epoch_train_acc = []\n",
    "    _train_acc =[]\n",
    "    \n",
    "    epoch_valid_acc = []\n",
    "    _valid_acc = []\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "\n",
    "\n",
    "        \n",
    "        for X_train_mini, y_train_mini in train_loader:\n",
    "            \n",
    "            ### preprocesing\n",
    "            \n",
    "            ##сплющивание тензора 3,28,28 --> 3.784\n",
    "            X_train_mini = torch.flatten(X_train_mini, start_dim=2, end_dim=3)\n",
    "            \n",
    "            ## меням тип на np.array 3, 785,1 \n",
    "            X_train_mini = np.array(X_train_mini) \n",
    "            \n",
    "            ## убиарем ось описывабщший батч\n",
    "            X_train_mini = np.squeeze(X_train_mini)\n",
    "            \n",
    "            # перемещавем ось\n",
    "            #X_train_mini = X_train_mini.swapaxes(0,2) \n",
    "            #print(X_train_mini .shape)\n",
    "            #стандартизируем данные\n",
    "            X_train_mini = model.standardize(normalize(X_train_mini))\n",
    "\n",
    "            \n",
    "            y_train_mini = np.array(y_train_mini)\n",
    "            #print(y_train_mini)\n",
    "\n",
    "\n",
    "            #### Compute outputs ####\n",
    "            z_out, a_out = model.forward(X_train_mini)\n",
    "            #print(\"a_out\", a_out)\n",
    "            \n",
    "            #### Compute delta ####\n",
    "            onehot_target = model.int_to_onehot(y_train_mini, num_labels=6)\n",
    "            #print('onehot_target', onehot_target)\n",
    "            \n",
    "            delta = (onehot_target  - a_out ) * learning_rate\n",
    "            #print('delta', delta)\n",
    "            \n",
    "            delta_weight = np.dot(delta.T, X_train_mini )\n",
    "            #print('delta_weight', delta_weight)\n",
    "\n",
    "            #### Update weights ####\n",
    "            model.weight_o +=  delta_weight.T\n",
    "            #print('weight_o', model.weight_o)\n",
    "\n",
    "            model.bias_o += np.sum(delta, axis=0)\n",
    "            #print('bias_o', model.bias_o)\n",
    "            \n",
    "            ##loss\n",
    "            predicted_labels = np.argmax(a_out, axis=1)\n",
    "            train_acc = (y_train_mini == predicted_labels)\n",
    "\n",
    "            train_mse =  ((onehot_target - a_out)**2)\n",
    "            \n",
    "            _train_acc.append(train_acc)\n",
    "            _loss.append(train_mse)\n",
    "            \n",
    "        for X_valid_mini, y_valid_mini in valid_loader:\n",
    "            \n",
    "            ##сплющивание тензора 3,28,28 --> 3.784\n",
    "            X_valid_mini = torch.flatten(X_valid_mini, start_dim=2, end_dim=3)\n",
    "            \n",
    "            ## меням тип на np.array 3, 785,1 \n",
    "            X_valid_mini = np.array(X_valid_mini) \n",
    "            \n",
    "            ## убиарем ось описывабщший батч\n",
    "            X_valid_mini = np.squeeze(X_valid_mini)\n",
    "            \n",
    "            # перемещавем ось\n",
    "            #X_train_mini = X_train_mini.swapaxes(0,2) \n",
    "\n",
    "            \n",
    "            #стандартизируем данные\n",
    "            X_valid_mini = model.standardize(normalize(X_valid_mini))\n",
    "\n",
    "            y_valid_mini = np.array(y_valid_mini)\n",
    "\n",
    "            \n",
    "            ##loss\n",
    "            \n",
    "            #### Compute outputs ####\n",
    "            _, a_v_out = model.forward(X_valid_mini)\n",
    "            \n",
    "            predicted_labels = np.argmax(a_v_out, axis=1)\n",
    "            \n",
    "            \n",
    "            valid_acc = (y_valid_mini == predicted_labels)\n",
    "            _valid_acc.append(valid_acc)\n",
    "\n",
    "            \n",
    "        #### Epoch Logging ####        \n",
    "        #train_mse, train_acc = compute_mse_and_acc(model, X_train_mini, y_train_mini)\n",
    "        #valid_mse, valid_acc = compute_mse_and_acc(model, X_valid, y_valid)\n",
    "        \n",
    "        \n",
    "        train_acc = np.mean(_train_acc) * 100\n",
    "        train_mse = np.mean(_loss)\n",
    "        \n",
    "        valid_acc = np.mean(_valid_acc) * 100\n",
    "        \n",
    "\n",
    "        epoch_train_acc.append(train_acc)\n",
    "        epoch_valid_acc.append(valid_acc)\n",
    "        epoch_loss.append(train_mse)\n",
    "        print(f'Epoch: {e+1:03d}/{num_epochs:.2f} '\n",
    "              f'| Train MSE: {train_mse:.2f} '\n",
    "              f'| Train Acc: {train_acc:.2f}% '\n",
    "              f'| Valid Acc: {valid_acc:.2f}%')\n",
    "\n",
    "    return epoch_loss, epoch_train_acc, epoch_valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/50.00 | Train MSE: 0.08 | Train Acc: 70.83% | Valid Acc: 33.33%\n",
      "Epoch: 002/50.00 | Train MSE: 0.06 | Train Acc: 79.17% | Valid Acc: 66.67%\n",
      "Epoch: 003/50.00 | Train MSE: 0.05 | Train Acc: 86.11% | Valid Acc: 77.78%\n",
      "Epoch: 004/50.00 | Train MSE: 0.04 | Train Acc: 89.58% | Valid Acc: 83.33%\n",
      "Epoch: 005/50.00 | Train MSE: 0.03 | Train Acc: 91.67% | Valid Acc: 86.67%\n",
      "Epoch: 006/50.00 | Train MSE: 0.03 | Train Acc: 93.06% | Valid Acc: 88.89%\n",
      "Epoch: 007/50.00 | Train MSE: 0.02 | Train Acc: 94.05% | Valid Acc: 90.48%\n",
      "Epoch: 008/50.00 | Train MSE: 0.02 | Train Acc: 94.79% | Valid Acc: 91.67%\n",
      "Epoch: 009/50.00 | Train MSE: 0.02 | Train Acc: 95.37% | Valid Acc: 92.59%\n",
      "Epoch: 010/50.00 | Train MSE: 0.02 | Train Acc: 95.83% | Valid Acc: 93.33%\n",
      "Epoch: 011/50.00 | Train MSE: 0.01 | Train Acc: 96.21% | Valid Acc: 93.94%\n",
      "Epoch: 012/50.00 | Train MSE: 0.01 | Train Acc: 96.53% | Valid Acc: 94.44%\n",
      "Epoch: 013/50.00 | Train MSE: 0.01 | Train Acc: 96.79% | Valid Acc: 94.87%\n",
      "Epoch: 014/50.00 | Train MSE: 0.01 | Train Acc: 97.02% | Valid Acc: 95.24%\n",
      "Epoch: 015/50.00 | Train MSE: 0.01 | Train Acc: 97.22% | Valid Acc: 95.56%\n",
      "Epoch: 016/50.00 | Train MSE: 0.01 | Train Acc: 97.40% | Valid Acc: 95.83%\n",
      "Epoch: 017/50.00 | Train MSE: 0.01 | Train Acc: 97.55% | Valid Acc: 96.08%\n",
      "Epoch: 018/50.00 | Train MSE: 0.01 | Train Acc: 97.69% | Valid Acc: 96.30%\n",
      "Epoch: 019/50.00 | Train MSE: 0.01 | Train Acc: 97.81% | Valid Acc: 96.49%\n",
      "Epoch: 020/50.00 | Train MSE: 0.01 | Train Acc: 97.92% | Valid Acc: 96.67%\n",
      "Epoch: 021/50.00 | Train MSE: 0.01 | Train Acc: 98.02% | Valid Acc: 96.83%\n",
      "Epoch: 022/50.00 | Train MSE: 0.01 | Train Acc: 98.11% | Valid Acc: 96.97%\n",
      "Epoch: 023/50.00 | Train MSE: 0.01 | Train Acc: 98.19% | Valid Acc: 97.10%\n",
      "Epoch: 024/50.00 | Train MSE: 0.01 | Train Acc: 98.26% | Valid Acc: 97.22%\n",
      "Epoch: 025/50.00 | Train MSE: 0.01 | Train Acc: 98.33% | Valid Acc: 97.33%\n",
      "Epoch: 026/50.00 | Train MSE: 0.01 | Train Acc: 98.40% | Valid Acc: 97.44%\n",
      "Epoch: 027/50.00 | Train MSE: 0.01 | Train Acc: 98.46% | Valid Acc: 97.53%\n",
      "Epoch: 028/50.00 | Train MSE: 0.01 | Train Acc: 98.51% | Valid Acc: 97.62%\n",
      "Epoch: 029/50.00 | Train MSE: 0.01 | Train Acc: 98.56% | Valid Acc: 97.70%\n",
      "Epoch: 030/50.00 | Train MSE: 0.01 | Train Acc: 98.61% | Valid Acc: 97.78%\n",
      "Epoch: 031/50.00 | Train MSE: 0.01 | Train Acc: 98.66% | Valid Acc: 97.85%\n",
      "Epoch: 032/50.00 | Train MSE: 0.01 | Train Acc: 98.70% | Valid Acc: 97.92%\n",
      "Epoch: 033/50.00 | Train MSE: 0.01 | Train Acc: 98.74% | Valid Acc: 97.98%\n",
      "Epoch: 034/50.00 | Train MSE: 0.00 | Train Acc: 98.77% | Valid Acc: 98.04%\n",
      "Epoch: 035/50.00 | Train MSE: 0.00 | Train Acc: 98.81% | Valid Acc: 98.10%\n",
      "Epoch: 036/50.00 | Train MSE: 0.00 | Train Acc: 98.84% | Valid Acc: 98.15%\n",
      "Epoch: 037/50.00 | Train MSE: 0.00 | Train Acc: 98.87% | Valid Acc: 98.20%\n",
      "Epoch: 038/50.00 | Train MSE: 0.00 | Train Acc: 98.90% | Valid Acc: 98.25%\n",
      "Epoch: 039/50.00 | Train MSE: 0.00 | Train Acc: 98.93% | Valid Acc: 98.29%\n",
      "Epoch: 040/50.00 | Train MSE: 0.00 | Train Acc: 98.96% | Valid Acc: 98.33%\n",
      "Epoch: 041/50.00 | Train MSE: 0.00 | Train Acc: 98.98% | Valid Acc: 98.37%\n",
      "Epoch: 042/50.00 | Train MSE: 0.00 | Train Acc: 99.01% | Valid Acc: 98.41%\n",
      "Epoch: 043/50.00 | Train MSE: 0.00 | Train Acc: 99.03% | Valid Acc: 98.45%\n",
      "Epoch: 044/50.00 | Train MSE: 0.00 | Train Acc: 99.05% | Valid Acc: 98.48%\n",
      "Epoch: 045/50.00 | Train MSE: 0.00 | Train Acc: 99.07% | Valid Acc: 98.52%\n",
      "Epoch: 046/50.00 | Train MSE: 0.00 | Train Acc: 99.09% | Valid Acc: 98.55%\n",
      "Epoch: 047/50.00 | Train MSE: 0.00 | Train Acc: 99.11% | Valid Acc: 98.58%\n",
      "Epoch: 048/50.00 | Train MSE: 0.00 | Train Acc: 99.13% | Valid Acc: 98.61%\n",
      "Epoch: 049/50.00 | Train MSE: 0.00 | Train Acc: 99.15% | Valid Acc: 98.64%\n",
      "Epoch: 050/50.00 | Train MSE: 0.00 | Train Acc: 99.17% | Valid Acc: 98.67%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123) # for the training set shuffling\n",
    "\n",
    "epoch_loss, epoch_train_acc, epoch_valid_acc = train(\n",
    "    model, train_loader, test_loader, num_epochs=50, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.08563060e-03,  9.97345447e-04,  2.82978498e-04,\n",
       "        -1.50629471e-03, -5.78600252e-04,  1.65143654e-03],\n",
       "       [-2.42667924e-03, -4.28912629e-04,  1.26593626e-03,\n",
       "        -8.66740402e-04, -6.78886152e-04, -9.47089689e-05],\n",
       "       [ 1.49138963e-03, -6.38901997e-04, -4.43981960e-04,\n",
       "        -4.34351276e-04,  2.20593008e-03,  2.18678609e-03],\n",
       "       ...,\n",
       "       [-4.54652365e-04,  2.47005806e-05, -2.05011003e-03,\n",
       "         6.39761168e-04,  1.42078645e-03,  1.24663078e-03],\n",
       "       [-1.04379345e-03,  5.98483986e-04,  5.16285804e-05,\n",
       "        -6.19840380e-04,  5.24523253e-04,  6.66086969e-04],\n",
       "       [ 4.48142609e-04,  4.94382376e-04, -9.34362341e-05,\n",
       "         1.65065342e-03, -8.45004127e-04,  3.95839030e-04]])"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка производительности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(epoch_loss)), epoch_loss)\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MSE\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод:\n",
    "\n",
    "    Издержки существенно уменьшаются в течение первых 10 эпох и,  медленно сходятся в последних 40 эпохах. Тем не менее, небольшой наклон между эпохами 40 и 50 указывает на то, что издержки продолжат снижаться, если обучение продолжится в добавочных эпохах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(epoch_train_acc)), epoch_train_acc)\n",
    "plt.plot(range(len(epoch_valid_acc)), epoch_valid_acc)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод:\n",
    "\n",
    "    Обнаруживается, что разрыв между правильностью при обучении и правильностью при проверке растет с увеличением числа эпох, в течение которых мы обучаем сеть. Примерно на 50-й эпохе значения правильности при обучении и правильности при проверке становятся равными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "_, out = model.forward(X)\n",
    "np.argmax(out, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Лабораторная работа 2: Обучение однослойного персептрона методом стохастического градиентного спуска\n",
    "\n",
    "__Студент:__ Семенов А.И.\n",
    "\n",
    "__Группа:__ МБД2032\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Цель работы. \n",
    "\n",
    "    Изучить алгоритм обучения однослойного персептрона методом стохастического градиентного спуска.\n",
    "\n",
    "\n",
    "### Задание\n",
    "\n",
    "    Построить и обучить нейронную сеть для распознавания цифровых рукописных символов из базы данных MNIST (Mixed National Institute of Standards and Technology database). Нейронная сеть должна корректно распознавать образы из тестовой выборки в большинстве случаев. Общий процент ошибки распознавания образов не должен быть выше 20%.\n",
    "\n",
    "### Теоретические сведения. \n",
    "\n",
    "Критерии останова алгоритма обучения могут быть следующими:\n",
    "\n",
    "* Значение ошибки ε для текущего обучающего вектора, вычисляемое на текущем случайно взятом обучающем векторе не превышает заданного заранее установленного порогового значения εпорог, близкого к нулю: ε<ε_порог.\n",
    "* Превышен установленный лимит количества эпох.\n",
    "* Значение общей ошибки всей сети меняется незначительно на протяжении нескольких эпох.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ход выполнения работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка предподготовленных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = np.load('mnist_scaled.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_train', 'y_train', 'X_test', 'y_test', 'X_valid', 'y_valid']"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, X_valid, y_valid = [mnist[f] for f in mnist.files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (55000, 784))"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train), X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNetMLP:\n",
    "    \n",
    "    \"\"\" \n",
    "    Нейронная сеть прямого распрастронения / классификатор \n",
    "    на основе многослойного персептрона\n",
    "    Параметры:\n",
    "    ---------\n",
    "    n_hidden : int (по умолчанию: 30)\n",
    "        количестов скрытых элементов\n",
    "    l2: float (по умолчанию: 0.)\n",
    "        значения лямбда для регулярщации L2\n",
    "        Регуляризация отстутствует, если l2=0 (принято по умолчанию).\n",
    "    epochs: int (по умолчанию: 100)\n",
    "        Количетсов проходов по обучающему набору.\n",
    "    lr: float (по умолчанию: 0.001)\n",
    "        скорость обучения \n",
    "    shuffle: bool (по умолчанию True)\n",
    "        Eсли True, тогда обучающие данные тасуются \n",
    "        каждую эпоху, чтобы предотвратить циклы\n",
    "    minibatch_size: int (по умолчанию 1)\n",
    "        Количество обучаюших образцов на минипакет\n",
    "    seed : int (по умолчанию:None)\n",
    "        Случайное начальное значение для инициализации весов и тасования\n",
    "        \n",
    "    Атрибуты:\n",
    "    --------\n",
    "    eval_ : dict\n",
    "        Словарь, в котором собираются показатели издержек,\n",
    "        правильности при обучении и правильности при испытании\n",
    "        для каждой эпохи во время обучения.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_features, num_labels,  num_classes, random_seed=123):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        # output layer инициализация весов для  слоя + баес\n",
    "        rgen = np.random.RandomState(random_seed)\n",
    "        self.weight_o = rgen.normal(loc=0.0, scale=0.001, size=( num_classes,num_features ))\n",
    "        self.bias_o = np.zeros(self.num_classes)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1. / (1. + np.exp(-z))\n",
    "    \n",
    "    def int_to_onehot(self, y, num_labels):\n",
    "        \n",
    "        ''' \n",
    "        Кодирует метки класса в представление с унитарным кодом\n",
    "        \n",
    "        Параметры:\n",
    "        ---------\n",
    "        y: массив, форма = [n_examples]\n",
    "            Целеые значения.\n",
    "            \n",
    "        Возвращает:\n",
    "        ----------\n",
    "        onehot : массив, форма = (n_examples, n_labels)\n",
    "        '''\n",
    "        onehot = np.zeros((y.shape[0], num_labels))\n",
    "        for indx, val in enumerate(y):\n",
    "            onehot[indx, val] = 1\n",
    "\n",
    "        return onehot \n",
    "    def forward(self, X):\n",
    "        \n",
    "        # 1 шаг прямого распространение скларяное произведение X и weight_h\n",
    "        z_out = np.dot(X, self.weight_o.T) + self.bias_o\n",
    "        \n",
    "        # 2 шаг применение функции активации (сигмоиды) - активация слоя\n",
    "        a_out = self.sigmoid(z_out)\n",
    "        \n",
    "        \n",
    "        return  X, a_out\n",
    "    \n",
    "    \n",
    "    def backward(self, x, a_out, y):\n",
    "        \n",
    "        ##########################\n",
    "        #Обратоне распространение#\n",
    "        ##########################\n",
    "        #########################\n",
    "        ### Output layer weights#\n",
    "        #########################\n",
    "        \n",
    "        #onehot encoding\n",
    "        y_onehot = self.int_to_onehot(y, self.num_classes)\n",
    "        \n",
    "        # Part 1: dLoss/dOutWeights\n",
    "        ## = dLoss/dOutAct(a_out) * dOutAct(a_out)/dOutNet(z_out) * dOutNet(z_out)/dOutWeight\n",
    "        ## where DeltaOut = dLoss/dOutAct * dOutAct/dOutNet\n",
    "        ## for convenient re-use\n",
    "        \n",
    "        # input/output dim: [n_examples, n_classes]\n",
    "        d_loss__d_a_out = 2.*(a_out - y_onehot) / y.shape[0]\n",
    "\n",
    "        # input/output dim: [n_examples, n_classes]\n",
    "        d_a_out__d_z_out = a_out * (1. - a_out) # sigmoid derivative\n",
    "\n",
    "        # output dim: [n_examples, n_classes]\n",
    "        delta_out = d_loss__d_a_out * d_a_out__d_z_out # \"delta (rule) placeholder\"\n",
    "\n",
    "        # gradient for output weights\n",
    "        \n",
    "        # [n_examples, n_hidden]\n",
    "        d_z_out__dw_out = x\n",
    "        \n",
    "        # input dim: [n_classes, n_examples] dot [n_examples, n_hidden]\n",
    "        # output dim: [n_classes, n_hidden]\n",
    "        d_loss__dw_out = np.dot(delta_out.T, d_z_out__dw_out)\n",
    "        d_loss__db_out = np.sum(delta_out, axis=0)\n",
    "        \n",
    "\n",
    "        return d_loss__dw_out, d_loss__db_out\n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetMLP(num_features=28*28,\n",
    "                     num_labels=10,\n",
    "                   num_classes=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch_size=100\n",
    "num_epochs =50\n",
    "\n",
    "def minibatch_generator(X, y, minibacth_size=50):\n",
    "    indices = np.arange(X.shape[0])\n",
    "    \n",
    "    \n",
    "    np.random.shuffle(indices)\n",
    "     \n",
    "    #итерация по мини-пакетам\n",
    "    for start_batch_indx in range(0, indices.shape[0] - minibatch_size + 1, minibatch_size):\n",
    "        indx = indices[start_batch_indx: start_batch_indx + minibatch_size]\n",
    "        yield X[indx], y[indx]\n",
    "        \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse_and_acc(nnet, X, y, num_labels=10, minibatch_size=100):\n",
    "    mse, correct_pred, num_examples = 0., 0, 0\n",
    "    minibatch_gen = minibatch_generator(X, y, minibatch_size)\n",
    "        \n",
    "    for i, (features, targets) in enumerate(minibatch_gen):\n",
    "\n",
    "        _, probas = nnet.forward(features)\n",
    "        predicted_labels = np.argmax(probas, axis=1)\n",
    "        \n",
    "        onehot_targets = nnet.int_to_onehot(targets, num_labels=num_labels)\n",
    "        loss = np.mean((onehot_targets - probas)**2)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "        \n",
    "        num_examples += targets.shape[0]\n",
    "        mse += loss\n",
    "\n",
    "    mse = mse/i\n",
    "    acc = correct_pred/num_examples\n",
    "    return mse, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial valid MSE: 0.3\n",
      "Initial valid accuracy: 10.2%\n"
     ]
    }
   ],
   "source": [
    "mse, acc = compute_mse_and_acc(model, X_valid, y_valid)\n",
    "print(f'Initial valid MSE: {mse:.1f}')\n",
    "print(f'Initial valid accuracy: {acc*100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, y_train, X_valid, y_valid, num_epochs, learning_rate=0.1):\n",
    "    \n",
    "    \n",
    "    ''' \n",
    "    Обновляем веса \n",
    "    \n",
    "    '''\n",
    "    epoch_loss = []\n",
    "    epoch_train_acc = []\n",
    "    epoch_valid_acc = []\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "\n",
    "        # iterate over minibatches\n",
    "        minibatch_gen = minibatch_generator(\n",
    "            X_train, y_train, minibatch_size)\n",
    "\n",
    "        for X_train_mini, y_train_mini in minibatch_gen:\n",
    "\n",
    "            #### Compute outputs ####\n",
    "            _, a_out = model.forward(X_train_mini)\n",
    "\n",
    "            #### Compute gradients ####\n",
    "            d_loss__d_w_out, d_loss__d_b_out = \\\n",
    "                model.backward(X_train_mini, a_out, y_train_mini)\n",
    "\n",
    "            #### Update weights ####\n",
    "            model.weight_o -= learning_rate * d_loss__d_w_out\n",
    "            model.bias_o -= learning_rate * d_loss__d_b_out\n",
    "\n",
    "        #### Epoch Logging ####        \n",
    "        train_mse, train_acc = compute_mse_and_acc(model, X_train, y_train)\n",
    "        valid_mse, valid_acc = compute_mse_and_acc(model, X_valid, y_valid)\n",
    "        train_acc, valid_acc = train_acc*100, valid_acc*100\n",
    "        epoch_train_acc.append(train_acc)\n",
    "        epoch_valid_acc.append(valid_acc)\n",
    "        epoch_loss.append(train_mse)\n",
    "        print(f'Epoch: {e+1:03d}/{num_epochs:03d} '\n",
    "              f'| Train MSE: {train_mse:.2f} '\n",
    "              f'| Train Acc: {train_acc:.2f}% '\n",
    "              f'| Valid Acc: {valid_acc:.2f}%')\n",
    "\n",
    "    return epoch_loss, epoch_train_acc, epoch_valid_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/050 | Train MSE: 0.09 | Train Acc: 10.56% | Valid Acc: 10.56%\n",
      "Epoch: 002/050 | Train MSE: 0.07 | Train Acc: 30.35% | Valid Acc: 30.30%\n",
      "Epoch: 003/050 | Train MSE: 0.05 | Train Acc: 56.26% | Valid Acc: 55.82%\n",
      "Epoch: 004/050 | Train MSE: 0.05 | Train Acc: 56.93% | Valid Acc: 56.46%\n",
      "Epoch: 005/050 | Train MSE: 0.04 | Train Acc: 66.24% | Valid Acc: 65.82%\n",
      "Epoch: 006/050 | Train MSE: 0.04 | Train Acc: 66.64% | Valid Acc: 66.46%\n",
      "Epoch: 007/050 | Train MSE: 0.04 | Train Acc: 66.73% | Valid Acc: 66.52%\n",
      "Epoch: 008/050 | Train MSE: 0.03 | Train Acc: 83.16% | Valid Acc: 83.42%\n",
      "Epoch: 009/050 | Train MSE: 0.02 | Train Acc: 83.60% | Valid Acc: 83.74%\n",
      "Epoch: 010/050 | Train MSE: 0.02 | Train Acc: 83.75% | Valid Acc: 83.70%\n",
      "Epoch: 011/050 | Train MSE: 0.02 | Train Acc: 84.04% | Valid Acc: 84.08%\n",
      "Epoch: 012/050 | Train MSE: 0.02 | Train Acc: 83.99% | Valid Acc: 84.04%\n",
      "Epoch: 013/050 | Train MSE: 0.02 | Train Acc: 84.07% | Valid Acc: 83.84%\n",
      "Epoch: 014/050 | Train MSE: 0.02 | Train Acc: 84.15% | Valid Acc: 83.82%\n",
      "Epoch: 015/050 | Train MSE: 0.02 | Train Acc: 84.07% | Valid Acc: 83.76%\n",
      "Epoch: 016/050 | Train MSE: 0.02 | Train Acc: 85.47% | Valid Acc: 85.12%\n",
      "Epoch: 017/050 | Train MSE: 0.02 | Train Acc: 91.05% | Valid Acc: 90.66%\n",
      "Epoch: 018/050 | Train MSE: 0.02 | Train Acc: 91.28% | Valid Acc: 90.84%\n",
      "Epoch: 019/050 | Train MSE: 0.02 | Train Acc: 91.26% | Valid Acc: 90.78%\n",
      "Epoch: 020/050 | Train MSE: 0.02 | Train Acc: 91.52% | Valid Acc: 90.90%\n",
      "Epoch: 021/050 | Train MSE: 0.02 | Train Acc: 91.51% | Valid Acc: 91.02%\n",
      "Epoch: 022/050 | Train MSE: 0.02 | Train Acc: 91.55% | Valid Acc: 91.12%\n",
      "Epoch: 023/050 | Train MSE: 0.02 | Train Acc: 91.63% | Valid Acc: 91.04%\n",
      "Epoch: 024/050 | Train MSE: 0.02 | Train Acc: 91.60% | Valid Acc: 91.04%\n",
      "Epoch: 025/050 | Train MSE: 0.02 | Train Acc: 91.68% | Valid Acc: 91.10%\n",
      "Epoch: 026/050 | Train MSE: 0.02 | Train Acc: 91.76% | Valid Acc: 91.22%\n",
      "Epoch: 027/050 | Train MSE: 0.02 | Train Acc: 91.80% | Valid Acc: 91.08%\n",
      "Epoch: 028/050 | Train MSE: 0.02 | Train Acc: 91.85% | Valid Acc: 91.30%\n",
      "Epoch: 029/050 | Train MSE: 0.02 | Train Acc: 91.84% | Valid Acc: 91.32%\n",
      "Epoch: 030/050 | Train MSE: 0.02 | Train Acc: 91.89% | Valid Acc: 91.26%\n",
      "Epoch: 031/050 | Train MSE: 0.02 | Train Acc: 91.86% | Valid Acc: 91.30%\n",
      "Epoch: 032/050 | Train MSE: 0.02 | Train Acc: 91.78% | Valid Acc: 91.10%\n",
      "Epoch: 033/050 | Train MSE: 0.02 | Train Acc: 91.87% | Valid Acc: 91.32%\n",
      "Epoch: 034/050 | Train MSE: 0.02 | Train Acc: 91.98% | Valid Acc: 91.26%\n",
      "Epoch: 035/050 | Train MSE: 0.02 | Train Acc: 91.90% | Valid Acc: 91.24%\n",
      "Epoch: 036/050 | Train MSE: 0.02 | Train Acc: 91.83% | Valid Acc: 91.04%\n",
      "Epoch: 037/050 | Train MSE: 0.02 | Train Acc: 91.96% | Valid Acc: 91.20%\n",
      "Epoch: 038/050 | Train MSE: 0.02 | Train Acc: 92.02% | Valid Acc: 91.26%\n",
      "Epoch: 039/050 | Train MSE: 0.02 | Train Acc: 91.95% | Valid Acc: 91.26%\n",
      "Epoch: 040/050 | Train MSE: 0.02 | Train Acc: 91.95% | Valid Acc: 91.22%\n",
      "Epoch: 041/050 | Train MSE: 0.02 | Train Acc: 92.10% | Valid Acc: 91.32%\n",
      "Epoch: 042/050 | Train MSE: 0.02 | Train Acc: 92.00% | Valid Acc: 91.30%\n",
      "Epoch: 043/050 | Train MSE: 0.01 | Train Acc: 92.13% | Valid Acc: 91.28%\n",
      "Epoch: 044/050 | Train MSE: 0.01 | Train Acc: 92.09% | Valid Acc: 91.28%\n",
      "Epoch: 045/050 | Train MSE: 0.01 | Train Acc: 92.19% | Valid Acc: 91.32%\n",
      "Epoch: 046/050 | Train MSE: 0.01 | Train Acc: 92.13% | Valid Acc: 91.30%\n",
      "Epoch: 047/050 | Train MSE: 0.01 | Train Acc: 92.20% | Valid Acc: 91.32%\n",
      "Epoch: 048/050 | Train MSE: 0.01 | Train Acc: 92.11% | Valid Acc: 91.32%\n",
      "Epoch: 049/050 | Train MSE: 0.01 | Train Acc: 92.21% | Valid Acc: 91.44%\n",
      "Epoch: 050/050 | Train MSE: 0.01 | Train Acc: 92.20% | Valid Acc: 91.40%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123) # for the training set shuffling\n",
    "\n",
    "epoch_loss, epoch_train_acc, epoch_valid_acc = train(\n",
    "    model, X_train, y_train, X_valid, y_valid,\n",
    "    num_epochs=50, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(epoch_loss)), epoch_loss)\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод:\n",
    "\n",
    "    Издержки существенно уменьшаются в течение первых 20 эпох и, кажется, медленно сходятся в последних 50 эпохах. Тем не менее, небольшой наклон между эпохами 40 и 50 указывает на то, что издержки продолжат снижаться, если обучение продолжится в добавочных эпохах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(epoch_train_acc)), epoch_train_acc)\n",
    "plt.plot(range(len(epoch_valid_acc)), epoch_valid_acc)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод:\n",
    "\n",
    "    Обнаруживается, что разрыв между правильностью при обучении и правильностью при проверке растет с увеличением числа эпох, в течение которых мы обучаем сеть. Примерно на 50-й эпохе значения правильности при обучении и правильности при проверке становятся равными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итог:\n",
    "\n",
    "    Во время обучения нейронной сети по-настоящему полезно сравнивать правильность при обучении и правильность при проверке, это помогает судить о том, хорошо ли работает сетевая модель с имеющейся архитектурой и гиперпараметрами. Например, если мы наблюдаем низкую правильность при обучении и при проверке, то весьма вероятно наличие проблемы с обучающим набором или же настройки гиперпараметров не являются идеальными. Относительно большой разрыв между правильностью при обучении и правильностью при проверке указывает на то, что модель, по всей видимости, переобучается обучающим набором данных, поэтому желательно уменьшить количество параметров в модели или увеличить силу регуляризации. Если правильность при обучении и правильность при проверке высоки, тогда модель, скорее всего, хорошо обобщается на новые данные, скажем, на испытательный набор, который мы используем для оценки финальной модели."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
